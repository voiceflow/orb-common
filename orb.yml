version: 2.1
description: Voiceflow's common CI/CD orb
executors:
  # Used to run tests
  code-test-executor:
    working_directory: ~/voiceflow # directory where steps will run
    resource_class: large
    environment:
      NODE_OPTIONS: --max-old-space-size=4096
    docker: # run the steps with Docker
      - image: circleci/node:12.20.2 # Test steps container
      - image: postgres:10.6-alpine # PostgresDB service container
        environment:
          POSTGRES_HOST_AUTH_METHOD: trust  # This is needed to ensure that the PG instance can be accessed locally without explicitly creating credentials
      - image: localstack/localstack:0.12.2 # Localstack to emulate AWS DynamoDB and S3 services
        environment:
        - EDGE_PORT=8000
        - SERVICES=s3,dynamodb
        - DEFAULT_REGION=us-east-1
        - DEBUG=1
      - image: circleci/redis:5.0-alpine # Redis service container
      - image: circleci/mongo:4.4.1 # MongoDB service container

  # Used to run container builds
  build-executor:
    working_directory: /tmp/vf-build
    docker:
      - image: voiceflow/ci-image:v3
    resource_class: medium

  # Used to run node-intensive tests and builds
  node-executor:
    working_directory: ~/voiceflow 
    docker: 
      - image: circleci/node:12.20.2 
    environment:
      NODE_OPTIONS: --max-old-space-size=4096
    resource_class: medium+

  default-executor: # used to run the release
    docker:
      - image: circleci/node:12.20.2
    resource_class: medium

#------------------------------------------------------------------ORBS---------------------------------------------------------------

orbs:
  slack: circleci/slack@4.2.1


#-------------------------------------------------------------------------------------------------------------------------------------

commands:

#-------------------------------------------------------------UTILS COMMANDS----------------------------------------------------------

  install_aws_cli:
    steps:
      - run:
          name: Install pip3
          command: sudo apt update && sudo apt install -y python3-pip
      - run:
          name: Install AWS CLI
          command: pip3 install awscli

  setup_pg:
    steps:
      - run:
          name: Install psql for seeding db
          command: |
            sudo apt update
            sudo apt install -y postgresql-client
      - run:
          name: Wait for Postgres & Dynamo Docker Images
          command: dockerize -wait tcp://localhost:5432 -timeout 1m 

  setup_dynamodb:
    steps:
      - run:
          name: AWS Config
          command: ./scripts/mock_aws_credentials.sh
      - run:
          name: Wait for Dynamo Docker Image
          command: dockerize -wait tcp://localhost:8000 -timeout 1m

  setup_mongodb:
    steps:
      - run:
          name: Wait for MongoDB Docker Image
          command: dockerize -wait tcp://localhost:27017 -timeout 1m
  
  clone_s3_assets:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Clone S3 assets
      from:
        description: S3 URL
        type: string
      to:
        description: Path to clone S3 assets
        type: string
    steps:
      - run:
          name: << parameters.step_name >>
          command: |
            aws s3 sync << parameters.from >> << parameters.to >>

  copy_s3_asset:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Copy S3 asset
      from:
        description: S3 URL
        type: string
      to:
        description: Path to copy S3 asset
        type: string
    steps:
      - run:
          name: << parameters.step_name >>
          command: |
            aws s3 cp << parameters.from >> << parameters.to >>

  clone_repo:
    parameters: 
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      github_commit:
        description: git commit hash for the repo provided
        type: env_var_name
        default: DEFAULT_COMMIT
      github_repo_name:
        description: github repo name
        type: string
      path_to_clone:
        description: Path to clone the github repo
        type: string
        default: './'
      step_name:
        description: Name of the step
        type: string
        default: Clone git repository
    steps:
      - run:
          name: << parameters.step_name >>
          command: |
            git clone https://${<< parameters.github_username >>}:${<< parameters.github_token >>}@github.com/voiceflow/<< parameters.github_repo_name >> << parameters.path_to_clone >>
            cd << parameters.path_to_clone >>
            git reset --hard ${<< parameters.github_commit >>}

  delete_branch:
    parameters: 
      branch_name:
        description: Name of the branch to delete
        type: string
      step_name:
        description: Name of the step
        type: string
        default: Delete branch
      ssh_key: 
        description: The SSH key with write permissions to the repository
        type: string
    steps:
      - add_ssh_keys: # To enable write access to repository for removing development environment branches
          fingerprints:
            - << parameters.ssh_key >>
      - run:
          name: << parameters.step_name >>
          command: |
            git push origin --delete << parameters.branch_name >> --no-verify # Clean up git branch

  check_image_exists:
    description: Check if a Docker image exists
    parameters: 
      image_repo: 
        description: The container image repository
        type: string
      request_remote_docker:
        description: Add the option to request a new remote docker, set to false when you concat docker jobs
        type: boolean
        default: true
    steps:
      - when:
          condition: << parameters.request_remote_docker >>
          steps:
            - setup_remote_docker:  # Need this to run DinD
                version: 19.03.13
      - run:
          name: If container with this git SHA already exists, don't build
          command: |
            IMAGE_REPO="<< parameters.image_repo >>"
            IMAGE_TAG="k8s-$CIRCLE_SHA1"
            IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
            $(aws ecr get-login --no-include-email --region us-east-1)
            set +e
            DOCKER_CLI_EXPERIMENTAL=enabled docker manifest inspect $IMAGE_NAME > /dev/null 2>&1
            SEARCH_IMAGE_RESULT=$?
            set -e
            
            # Store the result on a file in tmp folder to use in future steps
            if [[ $SEARCH_IMAGE_RESULT -eq 0 ]]; then  
              echo 'export IMAGE_EXISTS="true"' > /tmp/IMAGE_STATUS  # Image exists, skip following steps
            else
              echo 'export IMAGE_EXISTS="false"' > /tmp/IMAGE_STATUS  # Image exists, skip following steps
            fi

  notify_slack:
    description: Notify build status on Slack Channel
    parameters: 
      channel: 
        description: The Slack Channel where we receive the notification
        type: string
      event:
        description: event when the notify is triggered
        enum:
          - fail
          - pass
          - always
        type: enum
      template:
        description: Slack Message template
        type: string
      mentions:
        description: Mention on the slack channel
        type: string
        default: ""
      branch_pattern:
        description: Branch pattern to allow the notification to be sent
        type: string
        default: ".*"
    steps:
      - when:
          condition: << parameters.mentions >>
          steps:
            - slack/notify:
                channel: << parameters.channel >>
                event: << parameters.event >>
                mentions: << parameters.mentions >>
                template: << parameters.template >>
                branch_pattern: << parameters.branch_pattern >>
      - unless:
          condition: << parameters.mentions >>
          steps:
            - slack/notify:
                channel: << parameters.channel >>
                event: << parameters.event >>
                template: << parameters.template >>
                branch_pattern: << parameters.branch_pattern >>

  check_track_exists:
    description: Check if a track  exists
    parameters:
      component:
        description: The container image repository
        type: string
      bucket:
        description: The container image repository
        type: string
        default: "com.voiceflow.ci.assets"
    steps:
      - run:
          name: If track does not exists, don't build
          command: |

            BRANCH_NAME=$CIRCLE_BRANCH
            if [[ -z "$CIRCLE_BRANCH" && ! -z "$CIRCLE_TAG" ]]; then
              BRANCH_NAME="master"
            fi

            TRACK="tracks/<< parameters.component >>/$BRANCH_NAME"
            echo $TRACK
            set +e
            aws s3 cp s3://<< parameters.bucket >>/$TRACK /tmp/$TRACK
            SEARCH_TRACK_RESULT=$?
            set -e

            # Store the result on a file in tmp folder to use in future steps
            if [[ $SEARCH_TRACK_RESULT -eq 0 ]]; then  
              echo 'export TRACK_EXISTS="true"' > /tmp/TRACK_STATUS  # Track exists, skip following steps
            else
              echo 'export TRACK_EXISTS="false"' > /tmp/TRACK_STATUS  # Track exists, skip following steps
            fi

  update_database_track:
    description: Update Database Track
    parameters:
      component:
        description: The component type for development environment deployment
        type: string
      checkout:
        description: Determines if a checkout will be executed or not
        type: boolean
        default: true
      bucket:
        description: The container image repository
        type: string
        default: "com.voiceflow.ci.assets"
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout # special step to check out source code to working directory
      - check_track_exists:
          component: << parameters.component >>
      - run:
          name: Update Track
          command: |
            # Load TRACK_EXISTS variable from file previously stored in the tmp folder
            source "/tmp/TRACK_STATUS"

            set +e  # Don't exit on the any error (for semantic-release)
            npx semantic-release@17 --prepare --dry-run | tee sem_release.output  # print semver to screen and force return 0
            SEM_VER=$(cat sem_release.output | grep 'The next release version is' | awk '{print $NF}')  # Get release semver
            set -e  # Don't exit on the any error (for semantic-release)

            if [[ $TRACK_EXISTS == "true"  && ! -z "$SEM_VER" ]]; then
              # update the track
              TRACK="tracks/<< parameters.component >>/$CIRCLE_BRANCH"
              echo $TRACK
              echo $SEM_VER > /tmp/$TRACK
              aws s3 cp /tmp/$TRACK s3://<< parameters.bucket >>/$TRACK
            else
              echo "Track does not exist! avoiding update!"
            fi

  update_track:
    description: Update Component Track
    parameters:
      image_repo:
        description: The container image repository
        type: string
      component:
        description: The component type for development environment deployment
        type: string
      dockerfile:
        description: Name of the Dockerfile to build
        type: string
        default: Dockerfile
      attach_workspace_folder:
        description: Folder where the workspace will be attached
        type: string
        default: /tmp/vf-build
      checkout:
        description: Determines if a checkout will be executed or not
        type: boolean
        default: true
      request_remote_docker:
        description: Add the option to request a new remote docker, set to false when you concat docker jobs
        type: boolean
        default: true
      bucket:
        description: The container image repository
        type: string
        default: "com.voiceflow.ci.assets"
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout # special step to check out source code to working directory
      - when:
          condition: << parameters.request_remote_docker >>
          steps:
            - setup_remote_docker: # Need this to run DinD
                version: 19.03.13
      - attach_workspace:
          at: << parameters.attach_workspace_folder >>
      - check_image_exists:
          image_repo: << parameters.image_repo >>
          request_remote_docker: false
      - check_track_exists:
          component: << parameters.component >>
          bucket: << parameters.bucket >>
      - run:
          name: "Building image and uploading track"
          command: |
            # Load IMAGE_EXISTS variable from file previously stored in the tmp folder
            source "/tmp/IMAGE_STATUS"
            # Load TRACK_EXISTS variable from file previously stored in the tmp folder
            source "/tmp/TRACK_STATUS"

            BRANCH_NAME=$CIRCLE_BRANCH
            if [[ -z "$CIRCLE_BRANCH" && ! -z "$CIRCLE_TAG" ]]; then
              BRANCH_NAME="master"
            fi

            if [[ $TRACK_EXISTS == "true" ]]; then
              IMAGE_TAG="k8s-$CIRCLE_SHA1"
              IMAGE_REPO="<< parameters.image_repo >>"
              IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
              SEM_VER="$BRANCH_NAME-$CIRCLE_SHA1"

              if [[ $IMAGE_EXISTS == "false" ]]; then
                # Build Docker Image
                echo "Image not found, building..."
                $(aws ecr get-login --no-include-email --region us-east-1)
                docker build \
                  --build-arg NPM_TOKEN=//registry.npmjs.org/:_authToken=${NPM_TOKEN} \
                  --build-arg build_BUILD_NUM=${CIRCLE_BUILD_NUM} \
                  --build-arg build_BUILD_URL=${CIRCLE_BUILD_URL}	\
                  --build-arg build_GIT_SHA=${CIRCLE_SHA1} \
                  --build-arg build_SEM_VER=${SEM_VER} \
                  -f << parameters.dockerfile >> \
                  -t $IMAGE_NAME . 
                docker push $IMAGE_NAME
              fi

              # update the track
              TRACK="tracks/<< parameters.component >>/$BRANCH_NAME"
              echo $TRACK
              pip3 install yq
              # the file /tmp/$TRACK is downloaded in the check_track_exists step
              yq -y -i --arg tag "${IMAGE_TAG}" '."<< parameters.component >>".image.tag=$tag' /tmp/$TRACK
              aws s3 cp /tmp/$TRACK s3://<< parameters.bucket >>/$TRACK

            else
              echo "Track does not exist! avoiding update!"
            fi


#-------------------------------------------------------------YARN COMMANDS----------------------------------------------------------
  serverless_deploy:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      environment:
        description: envrionment where to deploy the serverless application
        type: string    
        default: dev
      run_in_backgorund:
        description: run the command in background
        type: boolean    
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Deploy application
      extra_args: 
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn serverless:deploy-<< parameters.environment >> << parameters.extra_args >>

  build:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_backgorund:
        description: run the command in background
        type: boolean    
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Build
      extra_args: 
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn build << parameters.extra_args >>

  lint_report:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean    
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Generate Lint report
      extra_args: 
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn lint:report << parameters.extra_args >>

  lint_source:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean    
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Lint source
      extra_args: 
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn lint:quiet << parameters.extra_args >>

  lint_dockerfile:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean    
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Lint dockerfiles
      extra_args: 
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: |
            sudo wget -O /usr/bin/hadolint https://github.com/hadolint/hadolint/releases/download/v1.19.0/hadolint-Linux-x86_64
            sudo chmod +x /usr/bin/hadolint
            yarn lint:dockerfiles << parameters.extra_args >>

  unit_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean    
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Unit Tests
      extra_args: 
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn test:unit << parameters.extra_args >>

  integration_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean    
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Integration Tests
      extra_args: 
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn test:integration << parameters.extra_args >>

  smoke_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean    
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Smoke tests
      extra_args: 
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn test:smoke << parameters.extra_args >>

  dependency_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean    
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Dependency tests
      extra_args: 
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn test:dependencies << parameters.extra_args >>


  tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_backgorund:
        description: run the command in background
        type: boolean    
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Run all tests
      extra_args: 
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn test << parameters.extra_args >>

  start_e2e:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_backgorund:
        description: run the command in background
        type: boolean    
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Start in e2e mode
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn e2e

  gen_certs:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      step_name:
        description: Name of the step
        type: string
        default: Generate certificates
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          name: << parameters.step_name >>
          command: yarn gen-certs

  gen_certs_e2e:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      step_name:
        description: Name of the step
        type: string
        default: Generate certificates for e2e tests
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          name: << parameters.step_name >>
          command: yarn gen-certs:e2e

  authenticate_npm:
    steps:
      - run:
          name: authenticate npm
          command: echo "//registry.npmjs.org/:_authToken=$NPM_TOKEN" >> ~/.npmrc

  save_node_module_cache:
    parameters:
      working_directory:
        description: Directory containing the yarn.lock file
        type: string
        default: './'
    steps:
      - save_cache:
          key: node-module-cache-<< parameters.working_directory >>-{{ checksum "<< parameters.working_directory >>/yarn.lock" }}
          paths:
            - << parameters.working_directory >>/node_modules

  restore_node_module_cache:
    parameters:
      working_directory:
        description: Directory containing the yarn.lock file
        type: string
        default: './'
    steps:
      - restore_cache:
          keys:
            - node-module-cache-<< parameters.working_directory >>-{{ checksum "<< parameters.working_directory >>/yarn.lock" }}

  install_node_modules:
    parameters:
      install_args:
        description: Additional yarn install command options
        type: string
        default: ""
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      yarn_lock_restore_cache_directory:
        description: Cache directory for yarn.lock file
        type: string
        default: './'
      avoid_post_install_scripts:
        description: Skip running post install scripts
        type: boolean
        default: true
    steps:
      - authenticate_npm
      - restore_cache:
          keys:
            - node-module-cache-{{ checksum "<< parameters.yarn_lock_restore_cache_directory >>/yarn.lock" }}
      - when:
          condition: << parameters.avoid_post_install_scripts >>
          steps:
            - run:
                working_directory: << parameters.working_directory >>
                name: yarn install packages
                command: yarn install --frozen-lockfile --ignore-scripts << parameters.install_args >>
      - unless:
          condition: << parameters.avoid_post_install_scripts >>
          steps:
            - run:
                working_directory: << parameters.working_directory >>
                name: yarn install packages
                command: yarn install --frozen-lockfile  << parameters.install_args >>
      - save_cache: # special step to save the dependency cache
          key: node-module-cache-{{ checksum "<< parameters.working_directory >>/yarn.lock" }}
          paths:
            - << parameters.working_directory >>/node_modules

#-------------------------------------------------------------DOCKER COMMANDS----------------------------------------------------------

  build_push_image: 
    parameters: 
      image_repo: 
        description: The container image repository
        type: string
      image_tag: 
        description: The container image tag
        type: string
        default: ""
      release_pkg: 
        description: The npm package name to be released
        type: string
        default: ""
      dockerfile: 
        description: Name of the Dockerfile to build
        type: string
        default: Dockerfile
      checkout: 
        description: Determines if a checkout will be executed or not
        type: boolean
        default: true
      request_remote_docker:
        description: Add the option to request a new remote docker, set to false when you concat docker jobs
        type: boolean
        default: true
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout # special step to check out source code to working directory
      - when:
          condition: << parameters.request_remote_docker >>
          steps:
            - setup_remote_docker:  # Need this to run DinD
                version: 19.03.13
      - run:
          name: "Build docker image"
          command: |
            IMAGE_TAG="<< parameters.image_tag >>"
            if [[ "$IMAGE_TAG" == "" ]]; then
              IMAGE_TAG="k8s-$CIRCLE_SHA1"
            fi
            IMAGE_REPO="<< parameters.image_repo >>"
            RELEASE_PKG="<< parameters.release_pkg >>"
            IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
            # Fix semantic versioning if a package is indicated, if not, semantic release are not executed
            if [[ "$CIRCLE_BRANCH" == "master" && "$RELEASE_PKG" != "" ]]; then
              npm config set unsafe-perm true # needed for npx to work
              set +e  # Don't exit on the any error (for semantic-release)
              npx semantic-release@17 --prepare --dry-run | tee sem_release.output  # print semver to screen and force return 0
              SEM_VER=$(cat sem_release.output | grep 'The next release version is' | awk '{print $NF}')  # Get release semver
              set -e  # Don't exit on the any error (for semantic-release)
              if [ -z "$SEM_VER" ]; then
                echo -e "//registry.npmjs.org/:_authToken=${NPM_TOKEN}" > ~/.npmrc
                SEM_VER=$(npm view << parameters.release_pkg >> version)
              fi
            else
              SEM_VER=$CIRCLE_BRANCH-$CIRCLE_SHA1
            fi
            echo -e "Building with SEM_VER=$SEM_VER"
            $(aws ecr get-login --no-include-email --region us-east-1)
            docker build \
              --build-arg NPM_TOKEN=//registry.npmjs.org/:_authToken=${NPM_TOKEN} \
              --build-arg build_BUILD_NUM=${CIRCLE_BUILD_NUM} \
              --build-arg build_BUILD_URL=${CIRCLE_BUILD_URL}	\
              --build-arg build_GIT_SHA=${CIRCLE_SHA1} \
              --build-arg build_SEM_VER=${SEM_VER} \
               -f << parameters.dockerfile >> \
              -t $IMAGE_NAME .
      - run:
          name: "Push docker images"
          command: |
            IMAGE_TAG="k8s-$CIRCLE_SHA1"
            IMAGE_REPO="<< parameters.image_repo >>"
            IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
            docker push $IMAGE_NAME
            BRANCH_NAME=$CIRCLE_BRANCH
            if [[ -z "$CIRCLE_BRANCH" && ! -z "$CIRCLE_TAG" ]]; then
              BRANCH_NAME="master"
            fi
            docker tag $IMAGE_NAME $IMAGE_REPO:latest-$BRANCH_NAME
            docker push $IMAGE_REPO:latest-$BRANCH_NAME

  post_image_push_actions: 
    description: Deploy an image into a K8s cluster
    parameters:
      target: 
        description: The target deployment/daemonset/statefulset prefix to modify
        type: string
        default: deployment/some-repo
      namespace:
        description: The namespace the target resides in 
        type: string
      tagged: 
        description: Running on a git tag?
        type: boolean
        default: false
      success_slack_notify: 
        description: Post to Slack on successful deployment?
        type: boolean
        default: true
      sentry:
        description: Report deployment to sentry
        type: boolean
        default: false
      ssh_key: 
        description: The SSH key with write permissions to the repository
        type: string
        default: "4c:f6:5f:e5:7a:e9:b4:03:91:6a:93:e5:0e:60:c2:a6"
    steps:
      - add_ssh_keys: # To enable write access to repository for removing development environment branches
          fingerprints:
            - << parameters.ssh_key >>
      - run:
          name: Post Image Push Actions
          command: |
            START_TIME=$(date +%s)

            if [[ "<< parameters.tagged >>" != "false" ]]; then
              sleep 60

              #Production
              aws eks --region us-east-1 update-kubeconfig --name production
                
              #Cloud Snapshot
              aws s3 cp s3://com.voiceflow.ci.assets/scripts/cloud_snapshot.sh cloud_snapshot.sh
              chmod +x cloud_snapshot.sh
              ./cloud_snapshot.sh << parameters.namespace >> << parameters.target >>

              #FIXME THIS IS A WA with a problem with the Slack Orb and dynamic templates
              export DEPLOY_TEMPLATE=$(cat /tmp/voiceflow/common/deploy_app_template.json)
              export SLACK_PARAM_TEMPLATE=DEPLOY_TEMPLATE
              export SLACK_PARAM_CHANNEL="deployed_versions"
              aws s3 cp s3://com.voiceflow.ci.assets/scripts/slack_notify.sh slack_notify.sh
              chmod +x slack_notify.sh
              ./slack_notify.sh

              if [[ "<< parameters.sentry >>" != "false" ]]; then
                END_TIME=$(date +%s)
                npm config set unsafe-perm true
                npx @sentry/cli@1 releases deploys "${CIRCLE_TAG:1}" new -e public -t $((END_TIME-START_TIME))
              fi
            fi

      - when:
          condition: << parameters.tagged >>
          steps:
            - when: 
                condition: <<parameters.success_slack_notify>>
                steps:
                - notify_slack:
                    channel: product_releases
                    event: pass
                    template: success_tagged_deploy_1
            - notify_slack:
                channel: product_releases
                event: fail
                mentions: "@engteam"
                template: basic_fail_1

#-------------------------------------------------------------E2E COMMANDS----------------------------------------------------------
  clone_vf_service:
    parameters:
      service_name:
        description: Name of the Voiceflow service
        type: string
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for service repo
        type: env_var_name
        default: DEFAULT_COMMIT
      yarn_install_extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - clone_repo:
          step_name: "Clone << parameters.service_name >> repository"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_repo_name: "<< parameters.service_name >>"
          github_commit: "<< parameters.commit >>"
          path_to_clone: "~/<< parameters.service_name >>"
      - restore_node_module_cache:
          working_directory: "~/<< parameters.service_name >>"
      - run:
          name: Generate e2e start script
          working_directory: "~/<< parameters.service_name >>"
          command: |
            cat > ./start_e2e.sh \<< \EOF
            #! /bin/bash

            set -e

            cd ~/<< parameters.service_name >>
            yarn install --frozen-lockfile --ignore-scripts << parameters.yarn_install_extra_args >>
            yarn gen-certs:e2e
            yarn e2e

            EOF

            chmod +x ./start_e2e.sh

  setup_vf_service:
    parameters: 
      service_name:
        description: Name of the Voiceflow service
        type: string
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for service repo
        type: env_var_name
        default: DEFAULT_COMMIT
      yarn_install_extra_args: 
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - clone_repo:
          step_name: "Clone << parameters.service_name >> repository"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_repo_name: "<< parameters.service_name >>"
          github_commit: "<< parameters.commit >>"
          path_to_clone: "~/<< parameters.service_name >>"
      - install_node_modules:
          install_args: "<< parameters.yarn_install_extra_args >>"
          avoid_post_install_scripts: false
          working_directory: "~/<< parameters.service_name >>"
          yarn_lock_restore_cache_directory: "~/<< parameters.service_name >>"
      - gen_certs_e2e:
          step_name: "Set up << parameters.service_name >>"
          working_directory: "~/<< parameters.service_name >>"
      - start_e2e:
          step_name: "Start << parameters.service_name >>"
          run_in_backgorund: true
          working_directory: "~/<< parameters.service_name >>"

  setup_vf_dbs:
    parameters: 
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
    steps:
      - clone_repo:
          step_name: "Clone database-cli repository"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_repo_name: database-cli
          github_commit: "<< parameters.commit >>"
          path_to_clone: ~/database-cli
      - install_node_modules:
          working_directory: ~/database-cli
          yarn_lock_restore_cache_directory: ~/database-cli
          install_args: --ignore-engines
      - run:
          name: Setup Database
          working_directory: ~/database-cli
          command: |
            yarn init:e2e

  setup_vf_creator_app:
    parameters: 
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for creator-app
        type: env_var_name
        default: DEFAULT_COMMIT
    steps:
      - checkout: 
          path: ~/creator-app
      - run:
          name: Setup Creator App
          working_directory: ~/creator-app
          command: |
            echo 'VF_APP_API_HOST=localhost' >> .env.local
            echo 'VF_APP_FF_DATA_REFACTOR=true' >> .env.local
      - install_node_modules:
          avoid_post_install_scripts: false
          working_directory: ~/creator-app
          yarn_lock_restore_cache_directory: ~/creator-app
      - gen_certs_e2e:
          step_name: Generate certificates Creator App
          working_directory: ~/creator-app
      - run:
          name: Setup Creator App
          working_directory: ~/creator-app
          no_output_timeout: 15m
          command: |
            yarn build:e2e
            yarn start:e2e

  setup_vf_creator_app_v2:
    parameters: 
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for creator-app
        type: env_var_name
        default: DEFAULT_COMMIT
    steps:
      - checkout: 
          path: ~/creator-app
      - run:
          name: Setup Creator App
          working_directory: ~/creator-app/packages/creator-app
          command: |
            echo 'VF_APP_API_HOST=localhost' >> .env.local
            echo 'VF_APP_FF_DATA_REFACTOR=true' >> .env.local
      - install_node_modules:
          avoid_post_install_scripts: false
          working_directory: ~/creator-app
          yarn_lock_restore_cache_directory: ~/creator-app
      - gen_certs_e2e:
          step_name: Generate certificates Creator App
          working_directory: ~/creator-app/packages/creator-app
      - run:
          name: Setup Creator App
          working_directory: ~/creator-app/packages/creator-app
          no_output_timeout: 15m
          command: |
            yarn build:e2e
            yarn start:e2e

#--------------------------------------------------------------------------------------------------------------------

jobs: 
  release:
    executor: node-executor
    parameters: 
      install_args: 
        description: Additional yarn install command options
        type: string
        default: ""
      sentry_project:
        description: Sentry project to associate the release with
        type: string
        default: ""
      avoid_post_install_scripts:
        description: Skip running post install scripts
        type: boolean
        default: true
    steps:
      - checkout
      - install_node_modules:
          install_args: "<< parameters.install_args >>"
          avoid_post_install_scripts: "<< parameters.avoid_post_install_scripts >>"
      - run: 
          name: Release Package
          command: |
            SENTRY_PROJECT=<< parameters.sentry_project >> npx semantic-release@17

  release_monorepo:
    executor: node-executor
    parameters: 
      install_args: 
        description: Additional yarn install command options
        type: string
        default: ""
      publish_args: 
        description: Additional lerna publish command options
        type: string
        default: ""
      sentry_project:
        description: Sentry project to associate the release with
        type: string
        default: ""
      avoid_post_install_scripts:
        description: Skip running post install scripts
        type: boolean
        default: true
      ssh_key: 
        description: The SSH key with write permissions to the repository
        type: string
    steps:
      - add_ssh_keys: # To enable write access to repository for removing development environment branches
          fingerprints:
            - << parameters.ssh_key >>
      - checkout
      - install_node_modules:
          install_args: "<< parameters.install_args >>"
          avoid_post_install_scripts: "<< parameters.avoid_post_install_scripts >>"
      - build
      - run: 
          name: Release Monorepo
          command: |
            git config --global user.email "serviceaccount@voiceflow.com"
            git config --global user.name "Voiceflow"
            SENTRY_PROJECT=<< parameters.sentry_project >> HUSKY=0 npx lerna@4.0.0 publish --message "chore(release): publish" --yes --conventional-commits --no-verify-access << parameters.publish_args >>

  generate_technical_documentation:
    executor: node-executor
    parameters: 
      step_name:
        description: Name of the step
        type: string
        default: Generate technical documentation
    steps:
      - run:
          name: << parameters.step_name >>
          command: curl -X POST -d {} https://api.netlify.com/build_hooks/${NETLIFY_TOKEN}

  test_e2e:
    resource_class: xlarge
    docker: # run the steps with Docker
      - image: cypress/base:12 # Test steps container
        environment:
          DEFAULT_COMMIT: master
          DOCKER_COMPOSE_VERSION: '1.24.1'
          DOCKERIZE_VERSION: v0.6.1
          MKCERT_VERSION: v1.4.0
          NODE_OPTIONS: --max_old_space_size=8192
      - image: postgres:10.6-alpine # PostgresDB service container
        environment:
          POSTGRES_HOST_AUTH_METHOD: trust
      - image: localstack/localstack:0.12.2 # Localstack to emulate AWS DynamoDB and S3 services
        environment:
        - EDGE_PORT=8000
        - SERVICES=s3,dynamodb
        - DEFAULT_REGION=us-east-1
        - DEBUG=1
      - image: circleci/mongo:4.4.1 # MongoDB service container
      - image: redis:5-alpine # Redis service container
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      creator_api_commit:
        description: git commit hash for creator-api
        type: env_var_name
        default: DEFAULT_COMMIT
      creator_app_commit:
        description: git commit hash for creator-app
        type: env_var_name
        default: DEFAULT_COMMIT
      database_cli_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
      server_data_api_commit:
        description: git commit hash for server-data-api
        type: env_var_name
        default: DEFAULT_COMMIT
      alexa_service_commit:
        description: git commit hash for alexa-service
        type: env_var_name
        default: DEFAULT_COMMIT
    steps:
      - run:
          name: Setup environment
          command: |
            apt update
            apt install -y nginx postgresql-client wget libnss3-tools apt-transport-https ca-certificates curl gnupg-agent software-properties-common
            curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add -
            add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable"
            apt update
            apt install -y docker-ce-cli

            wget https://github.com/FiloSottile/mkcert/releases/download/$MKCERT_VERSION/mkcert-$MKCERT_VERSION-linux-amd64
            chmod +x mkcert-$MKCERT_VERSION-linux-amd64
            mv mkcert-$MKCERT_VERSION-linux-amd64 /usr/local/bin/mkcert
            mkcert -install

            wget https://github.com/jwilder/dockerize/releases/download/$DOCKERIZE_VERSION/dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            tar -C /usr/local/bin -xzvf dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            rm dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz

            curl -L "https://github.com/docker/compose/releases/download/$DOCKER_COMPOSE_VERSION/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
            chmod +x /usr/local/bin/docker-compose
      - setup_vf_dbs:
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_creator_app_v2:
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - run:
          name: Wait for databases to come online
          command: |
            dockerize -wait tcp://localhost:5432 -timeout 1m \
            && dockerize -wait tcp://localhost:8000 -timeout 1m  
      - setup_vf_service:
          service_name: server-data-api
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_service:
          service_name: creator-api
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_service:
          service_name: alexa-service
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_service:
          service_name: alexa-runtime
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_service:
          service_name: general-service
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_service:
          service_name: general-runtime
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_service:
          service_name: google-service
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_service:
          service_name: google-runtime
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_service:
          service_name: canvas-export
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_service:
          service_name: luis-authoring-service
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_service:
          service_name: integrations
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_service:
          service_name: custom-api
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
          yarn_install_extra_args: "--ignore-engines"
      - run:
          name: Wait for services to come online
          command: |
            dockerize -wait tcp://localhost:8001 -timeout 1m \
            && dockerize -wait tcp://localhost:8002 -timeout 1m \
            && dockerize -wait tcp://localhost:8003 -timeout 1m \
            && dockerize -wait tcp://localhost:8004 -timeout 1m \
            && dockerize -wait tcp://localhost:8005 -timeout 1m \
            && dockerize -wait tcp://localhost:8006 -timeout 1m \
            && dockerize -wait tcp://localhost:8007 -timeout 1m \
            && dockerize -wait tcp://localhost:8008 -timeout 1m \
            && dockerize -wait tcp://localhost:8009 -timeout 1m \
            && dockerize -wait tcp://localhost:8010 -timeout 1m \
            && dockerize -wait tcp://localhost:8011 -timeout 1m \
            && dockerize -wait tcp://localhost:8012 -timeout 1m 
      - run:
          name: Run Cypress Tests
          working_directory: ~/creator-app/packages/creator-app
          command: yarn cypress:ci
      - store_artifacts:
          path: ~/creator-app/packages/creator-app/cypress/videos
      - store_artifacts:
          path: ~/creator-app/packages/creator-app/cypress/screenshots

  test_parallel_e2e:
    resource_class: xlarge
    docker: # run the steps with Docker
      - image: cypress/base:12 # Test steps container
        environment:
          DEFAULT_COMMIT: master
          DOCKER_COMPOSE_VERSION: '1.24.1'
          DOCKERIZE_VERSION: v0.6.1
          MKCERT_VERSION: v1.4.0
          NODE_OPTIONS: --max_old_space_size=8192
      - image: postgres:10.6-alpine # PostgresDB service container
        environment:
          POSTGRES_HOST_AUTH_METHOD: trust
      - image: localstack/localstack:0.12.2 # Localstack to emulate AWS DynamoDB and S3 services
        environment:
        - EDGE_PORT=8000
        - SERVICES=s3,dynamodb
        - DEFAULT_REGION=us-east-1
        - DEBUG=1
      - image: circleci/mongo:4.4.1 # MongoDB service container
      - image: redis:5-alpine # Redis service container
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      creator_api_commit:
        description: git commit hash for creator-api
        type: env_var_name
        default: DEFAULT_COMMIT
      creator_app_commit:
        description: git commit hash for creator-app
        type: env_var_name
        default: DEFAULT_COMMIT
      database_cli_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
      server_data_api_commit:
        description: git commit hash for server-data-api
        type: env_var_name
        default: DEFAULT_COMMIT
      alexa_service_commit:
        description: git commit hash for alexa-service
        type: env_var_name
        default: DEFAULT_COMMIT
    steps:
      - run:
          name: Setup environment
          command: |
            apt update
            apt install -y nginx postgresql-client wget libnss3-tools apt-transport-https ca-certificates curl gnupg-agent software-properties-common
            curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add -
            add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable"
            apt update
            apt install -y docker-ce-cli

            wget https://github.com/FiloSottile/mkcert/releases/download/$MKCERT_VERSION/mkcert-$MKCERT_VERSION-linux-amd64
            chmod +x mkcert-$MKCERT_VERSION-linux-amd64
            mv mkcert-$MKCERT_VERSION-linux-amd64 /usr/local/bin/mkcert
            mkcert -install

            wget https://github.com/jwilder/dockerize/releases/download/$DOCKERIZE_VERSION/dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            tar -C /usr/local/bin -xzvf dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            rm dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz

            curl -L "https://github.com/docker/compose/releases/download/$DOCKER_COMPOSE_VERSION/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
            chmod +x /usr/local/bin/docker-compose
      - setup_vf_dbs:
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - setup_vf_creator_app_v2:
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          commit: << parameters.database_cli_commit >>
      - clone_vf_service:
          service_name: server-data-api
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
      - clone_vf_service:
          service_name: creator-api
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
      - clone_vf_service:
          service_name: alexa-service
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
      - clone_vf_service:
          service_name: alexa-runtime
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
      - clone_vf_service:
          service_name: general-service
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
      - clone_vf_service:
          service_name: general-runtime
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
      - clone_vf_service:
          service_name: google-service
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
      - clone_vf_service:
          service_name: google-runtime
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
      - clone_vf_service:
          service_name: canvas-export
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
      - clone_vf_service:
          service_name: luis-authoring-service
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
      - clone_vf_service:
          service_name: integrations
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
      - clone_vf_service:
          service_name: custom-api
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          yarn_install_extra_args: "--ignore-engines"
      - run:
          name: Wait for databases to come online
          command: |
            dockerize -wait tcp://localhost:5432 -timeout 1m \
            && dockerize -wait tcp://localhost:8000 -timeout 1m
      - run:
          name: Start services in e2e mode
          background: true
          command: |
            npx concurrently \
              '~/server-data-api/start_e2e.sh' \
              '~/creator-api/start_e2e.sh' \
              '~/alexa-service/start_e2e.sh' \
              '~/alexa-runtime/start_e2e.sh' \
              '~/general-service/start_e2e.sh' \
              '~/general-runtime/start_e2e.sh' \
              '~/google-service/start_e2e.sh' \
              '~/google-runtime/start_e2e.sh' \
              '~/canvas-export/start_e2e.sh' \
              '~/luis-authoring-service/start_e2e.sh' \
              '~/integrations/start_e2e.sh' \
              '~/custom-api/start_e2e.sh'
      - run:
          name: Wait for services to come online
          command: |
            dockerize -wait tcp://localhost:8001 -timeout 1m \
            && dockerize -wait tcp://localhost:8002 -timeout 1m \
            && dockerize -wait tcp://localhost:8003 -timeout 1m \
            && dockerize -wait tcp://localhost:8004 -timeout 1m \
            && dockerize -wait tcp://localhost:8005 -timeout 1m \
            && dockerize -wait tcp://localhost:8006 -timeout 1m \
            && dockerize -wait tcp://localhost:8007 -timeout 1m \
            && dockerize -wait tcp://localhost:8008 -timeout 1m \
            && dockerize -wait tcp://localhost:8009 -timeout 1m \
            && dockerize -wait tcp://localhost:8010 -timeout 1m \
            && dockerize -wait tcp://localhost:8011 -timeout 1m \
            && dockerize -wait tcp://localhost:8012 -timeout 1m
      - run:
          name: Run Cypress Tests
          working_directory: ~/creator-app/packages/creator-app
          command: yarn cypress:ci
      - save_node_module_cache:
          working_directory: ~/server-data-api
      - save_node_module_cache:
          working_directory: ~/creator-api
      - save_node_module_cache:
          working_directory: ~/alexa-service
      - save_node_module_cache:
          working_directory: ~/alexa-runtime
      - save_node_module_cache:
          working_directory: ~/general-service
      - save_node_module_cache:
          working_directory: ~/general-runtime
      - save_node_module_cache:
          working_directory: ~/google-service
      - save_node_module_cache:
          working_directory: ~/google-runtime
      - save_node_module_cache:
          working_directory: ~/canvas-export
      - save_node_module_cache:
          working_directory: ~/luis-authoring-service
      - save_node_module_cache:
          working_directory: ~/integrations
      - save_node_module_cache:
          working_directory: ~/custom-api
      - store_artifacts:
          path: ~/creator-app/packages/creator-app/cypress/videos
      - store_artifacts:
          path: ~/creator-app/packages/creator-app/cypress/screenshots
