version: 2.1
description: Voiceflow's common CI/CD orb
executors:
  e2e-executor:
    resource_class: xlarge
    docker: # run the steps with Docker
      - image: 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
        environment:
          DEFAULT_COMMIT: master
          DOCKER_COMPOSE_VERSION: '1.24.1'
          DOCKERIZE_VERSION: v0.6.1
          MKCERT_VERSION: v1.4.0
          NODE_OPTIONS: --max_old_space_size=8192
      - image: postgres:10.6-alpine # PostgresDB service container
        environment:
          POSTGRES_HOST_AUTH_METHOD: trust
      - image: localstack/localstack:0.12.2 # Localstack to emulate AWS DynamoDB and S3 services
        environment:
        - EDGE_PORT=8000
        - SERVICES=s3,dynamodb
        - DEFAULT_REGION=us-east-1
        - DEBUG=1
      - image: circleci/mongo:4.4.1 # MongoDB service container
      - image: redis:5-alpine # Redis service container

  # Used to run tests
  code-test-executor:
    working_directory: ~/voiceflow # directory where steps will run
    resource_class: large
    environment:
      NODE_OPTIONS: --max-old-space-size=4096
    docker: # run the steps with Docker
      - image: circleci/node:16.13.0 # Test steps container
      - image: postgres:10.6-alpine # PostgresDB service container
        environment:
          POSTGRES_HOST_AUTH_METHOD: trust  # This is needed to ensure that the PG instance can be accessed locally without explicitly creating credentials
      - image: localstack/localstack:0.12.2 # Localstack to emulate AWS DynamoDB and S3 services
        environment:
        - EDGE_PORT=8000
        - SERVICES=s3,dynamodb
        - DEFAULT_REGION=us-east-1
        - DEBUG=1
      - image: circleci/redis:5.0-alpine # Redis service container
      - image: circleci/mongo:4.4.1 # MongoDB service container

  # Used to run container builds
  build-executor:
    working_directory: /tmp/vf-build
    docker:
      - image: 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-image:v4
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: medium

  # Used to run node-intensive tests and builds
  node-executor:
    working_directory: ~/voiceflow
    docker:
      - image: circleci/node:16.13.0
    environment:
      NODE_OPTIONS: --max-old-space-size=4096
    resource_class: medium+

  default-executor: # used to run the release
    docker:
      - image: circleci/node:16.13.0
    resource_class: medium

  # for go executions
  go-executor:
    resource_class: medium+
    docker:
      - image: cimg/go:1.16

#------------------------------------------------------------------ORBS---------------------------------------------------------------

orbs:
  slack: circleci/slack@4.2.1
  gh: circleci/github-cli@1.0


#-------------------------------------------------------------------------------------------------------------------------------------

#-------------------------------------------------------------HELM COMMANDS----------------------------------------------------------

commands:
  helm-add-repos:
    description: Add voiceflow Helm repos
    steps:
      - run:
          name: Add voiceflow Helm repos
          command: |
            helm repo add voiceflow-charts-s3 s3://voiceflow-charts 
            helm repo add voiceflow-charts-s3-private s3://voiceflow-charts-private
            helm repo add voiceflow-charts-s3-beta s3://voiceflow-charts-beta
            helm repo update

  helm-package-publish-charts:
    description: Package and publish helm charts
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
    steps:
      - run:
          name: Package and publish charts
          working_directory: << parameters.working_directory >>
          command: |
            for file in */ ; do 
              if [[ -d "$file" && -f "$file/$file/Chart.yaml" ]]; then
                echo "packaging $file";
                cd $file;
                helm dep update $file;
                helm package $file;
                pattern="*.tgz";
                chart=( $pattern );
                channel=$(cat $file/Chart.yaml | yq -r '.annotations."release-channel"')
                echo "publishing in $channel channel";
                if [[ $channel == "private" ]]; then
                  helm s3 push --force ${chart[0]} voiceflow-charts-s3-private;
                fi
                if [[ $channel == "public" ]]; then
                  helm s3 push --force ${chart[0]} voiceflow-charts-s3;
                fi
                if [[ $channel == "beta" ]]; then
                  helm s3 push --force ${chart[0]} voiceflow-charts-s3-beta;
                fi
                cd ..;
              fi; 
            done

#-------------------------------------------------------------UTILS COMMANDS----------------------------------------------------------

  set_yarn_bash_default_shell:
    steps:
      - run:
          name: Set Bash as a default shell for yarn commands
          command: yarn config set script-shell /bin/bash


  install_aws_cli:
    steps:
      - run:
          name: Install pip3
          command: sudo apt update && sudo apt install -y python3-pip
      - run:
          name: Install AWS CLI
          command: pip3 install awscli

  install_hadolint:
    description: Install Hadolint
    steps:
      - run:
          name: Install Hadolint
          command: |
            sudo wget -O /usr/bin/hadolint https://github.com/hadolint/hadolint/releases/download/v1.19.0/hadolint-Linux-x86_64
            sudo chmod +x /usr/bin/hadolint

  install_cpio:
    description: Install cpio
    steps:
      - run:
          name: Install cpio
          command: |
            sudo apt-get install -y cpio || apt-get install -y cpio

  setup_pg:
    steps:
      - run:
          name: Install psql for seeding db
          command: |
            sudo apt update
            sudo apt install -y postgresql-client
      - run:
          name: Wait for Postgres & Dynamo Docker Images
          command: dockerize -wait tcp://localhost:5432 -timeout 1m

  setup_dynamodb:
    steps:
      - run:
          name: AWS Config
          command: ./scripts/mock_aws_credentials.sh
      - run:
          name: Wait for Dynamo Docker Image
          command: dockerize -wait tcp://localhost:8000 -timeout 1m

  setup_mongodb:
    steps:
      - run:
          name: Wait for MongoDB Docker Image
          command: dockerize -wait tcp://localhost:27017 -timeout 1m

  clone_s3_assets:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Clone S3 assets
      from:
        description: S3 URL
        type: string
      to:
        description: Path to clone S3 assets
        type: string
    steps:
      - run:
          name: << parameters.step_name >>
          command: |
            aws s3 sync << parameters.from >> << parameters.to >>

  copy_s3_asset:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Copy S3 asset
      from:
        description: S3 URL
        type: string
      to:
        description: Path to copy S3 asset
        type: string
    steps:
      - run:
          name: << parameters.step_name >>
          command: |
            aws s3 cp << parameters.from >> << parameters.to >>

  set_etc_hosts_e2e:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Set etc hosts
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
    steps:
      - run:
          name: << parameters.step_name >>
          background: << parameters.run_in_background >>
          command: |
            # Modify the hosts of the executor
            set +e
            # with sudo - machine executor
            echo '127.0.0.1 creator-app.test.e2e postgres.test.e2e redis.test.e2e localstack.test.e2e mongodb.test.e2e server-data-api.test.e2e creator-api.test.e2e luis-authoring-service.test.e2e integrations.test.e2e custom-api.test.e2e canvas-export.test.e2e alexa-runtime.test.e2e alexa-service.test.e2e general-runtime.test.e2e general-service.test.e2e google-runtime.test.e2e google-service.test.e2e realtime.test.e2e ingest.test.e2e' | sudo tee -a /etc/hosts > /dev/null
            # without sudo - docker executor
            echo '127.0.0.1 creator-app.test.e2e postgres.test.e2e redis.test.e2e localstack.test.e2e mongodb.test.e2e server-data-api.test.e2e creator-api.test.e2e luis-authoring-service.test.e2e integrations.test.e2e custom-api.test.e2e canvas-export.test.e2e alexa-runtime.test.e2e alexa-service.test.e2e general-runtime.test.e2e general-service.test.e2e google-runtime.test.e2e google-service.test.e2e realtime.test.e2e ingest.test.e2e' | tee -a /etc/hosts > /dev/null
            set -e

  clone_repo:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      github_commit:
        description: git commit hash for the repo provided
        type: env_var_name
        default: DEFAULT_COMMIT
      github_repo_name:
        description: github repo name
        type: string
      path_to_clone:
        description: Path to clone the github repo
        type: string
        default: './'
      step_name:
        description: Name of the step
        type: string
        default: Clone git repository
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
    steps:
      - run:
          name: << parameters.step_name >>
          background: << parameters.run_in_background >>
          command: |
            git clone https://${<< parameters.github_username >>}:${<< parameters.github_token >>}@github.com/voiceflow/<< parameters.github_repo_name >> << parameters.path_to_clone >>
            cd << parameters.path_to_clone >>
            git reset --hard ${<< parameters.github_commit >>}

  delete_branch:
    parameters:
      branch_name:
        description: Name of the branch to delete
        type: string
      step_name:
        description: Name of the step
        type: string
        default: Delete branch
      ssh_key:
        description: The SSH key with write permissions to the repository
        type: string
    steps:
      - add_ssh_keys: # To enable write access to repository for removing development environment branches
          fingerprints:
            - << parameters.ssh_key >>
      - run:
          name: << parameters.step_name >>
          command: |
            git push origin --delete << parameters.branch_name >> --no-verify # Clean up git branch

  check_image_exists:
    description: Check if a Docker image exists
    parameters:
      image_repo:
        description: The container image repository
        type: string
      request_remote_docker:
        description: Add the option to request a new remote docker, set to false when you concat docker jobs
        type: boolean
        default: true
    steps:
      - when:
          condition: << parameters.request_remote_docker >>
          steps:
            - setup_remote_docker:  # Need this to run DinD
                version: 19.03.13
      - run:
          name: If container with this git SHA already exists, don't build
          command: |
            IMAGE_REPO="<< parameters.image_repo >>"
            IMAGE_TAG="k8s-$CIRCLE_SHA1"
            IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
            $(aws ecr get-login --no-include-email --region us-east-1)
            set +e
            DOCKER_CLI_EXPERIMENTAL=enabled docker manifest inspect $IMAGE_NAME > /dev/null 2>&1
            SEARCH_IMAGE_RESULT=$?
            set -e

            # Store the result on a file in tmp folder to use in future steps
            if [[ $SEARCH_IMAGE_RESULT -eq 0 ]]; then
              echo 'export IMAGE_EXISTS="true"' > /tmp/IMAGE_STATUS  # Image exists, skip following steps
            else
              echo 'export IMAGE_EXISTS="false"' > /tmp/IMAGE_STATUS  # Image exists, skip following steps
            fi

  notify_slack:
    description: Notify build status on Slack Channel
    parameters:
      channel:
        description: The Slack Channel where we receive the notification
        type: string
      event:
        description: event when the notify is triggered
        enum:
          - fail
          - pass
          - always
        type: enum
      template:
        description: Slack Message template
        type: string
      mentions:
        description: Mention on the slack channel
        type: string
        default: ""
      branch_pattern:
        description: Branch pattern to allow the notification to be sent
        type: string
        default: ".*"
    steps:
      - when:
          condition: << parameters.mentions >>
          steps:
            - slack/notify:
                channel: << parameters.channel >>
                event: << parameters.event >>
                mentions: << parameters.mentions >>
                template: << parameters.template >>
                branch_pattern: << parameters.branch_pattern >>
      - unless:
          condition: << parameters.mentions >>
          steps:
            - slack/notify:
                channel: << parameters.channel >>
                event: << parameters.event >>
                template: << parameters.template >>
                branch_pattern: << parameters.branch_pattern >>

  check_track_exists:
    description: Check if a track  exists
    parameters:
      component:
        description: The container image repository
        type: string
      bucket:
        description: The container image repository
        type: string
        default: "com.voiceflow.ci.assets"
      stop_if_not_exists:
        description: Stop if the bucket does not exists
        type: boolean
        default: false
    steps:
      - run:
          name: If track does not exists, don't build
          command: |

            STOP=<< parameters.stop_if_not_exists >>

            BRANCH_NAME=$CIRCLE_BRANCH
            if [[ -z "$CIRCLE_BRANCH" && ! -z "$CIRCLE_TAG" ]]; then
              BRANCH_NAME="master"
            fi

            TRACK="tracks/<< parameters.component >>/$BRANCH_NAME"
            echo $TRACK
            set +e
            aws s3 cp s3://<< parameters.bucket >>/$TRACK /tmp/$TRACK
            SEARCH_TRACK_RESULT=$?
            set -e

            # Store the result on a file in tmp folder to use in future steps
            if [[ $SEARCH_TRACK_RESULT -eq 0 ]]; then
              echo 'export TRACK_EXISTS="true"' > /tmp/TRACK_STATUS  # Track exists, skip following steps
            else
              echo 'export TRACK_EXISTS="false"' > /tmp/TRACK_STATUS  # Track exists, skip following steps
              if [[ $STOP == true ]]; then
                curl --request POST \
                  --url https://circleci.com/api/v2/workflow/$CIRCLE_WORKFLOW_ID/cancel \
                  --header "Circle-Token: ${CIRCLECI_API_TOKEN}"
              fi
            fi

  update_database_track:
    description: Update Database Track
    parameters:
      component:
        description: The component type for development environment deployment
        type: string
      checkout:
        description: Determines if a checkout will be executed or not
        type: boolean
        default: true
      bucket:
        description: The container image repository
        type: string
        default: "com.voiceflow.ci.assets"
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout # special step to check out source code to working directory
      - check_track_exists:
          component: << parameters.component >>
      - run:
          name: Update Track
          command: |
            # Load TRACK_EXISTS variable from file previously stored in the tmp folder
            source "/tmp/TRACK_STATUS"

            set +e  # Don't exit on the any error (for semantic-release)
            npx semantic-release@17 --prepare --dry-run | tee sem_release.output  # print semver to screen and force return 0
            SEM_VER=$(cat sem_release.output | grep 'The next release version is' | awk '{print $NF}')  # Get release semver
            set -e  # Don't exit on the any error (for semantic-release)

            if [[ $TRACK_EXISTS == "true"  && ! -z "$SEM_VER" ]]; then
              # update the track
              TRACK="tracks/<< parameters.component >>/$CIRCLE_BRANCH"
              echo $TRACK
              echo $SEM_VER > /tmp/$TRACK
              aws s3 cp /tmp/$TRACK s3://<< parameters.bucket >>/$TRACK
            else
              echo "Track does not exist! avoiding update!"
            fi

  update_track:
    description: Update Component Track
    parameters:
      image_repo:
        description: The container image repository
        type: string
      component:
        description: The component type for development environment deployment
        type: string
      dockerfile:
        description: Name of the Dockerfile to build
        type: string
        default: Dockerfile
      build_args:
        description: Arguments to pass while building the docker image
        type: string
        default: ''
      build_context:
        description: Path to the context for the docker build
        type: string
        default: '.'
      checkout:
        description: Determines if a checkout will be executed or not
        type: boolean
        default: true
      request_remote_docker:
        description: Add the option to request a new remote docker, set to false when you concat docker jobs
        type: boolean
        default: true
      bucket:
        description: The container image repository
        type: string
        default: "com.voiceflow.ci.assets"
      check_track_exists:
        description: checks if the track exists
        type: boolean
        default: true
      local_registry:
        description: Use a local proxy registry to publish alpha version of all libraries in monorepo (must have a /config/verdaccio/config.yaml file)
        type: boolean
        default: false
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout # special step to check out source code to working directory
      - when:
          condition: << parameters.request_remote_docker >>
          steps:
            - setup_remote_docker: # Need this to run DinD
                version: 19.03.13
      - attach_workspace:
          at: /tmp/vf-build
      - check_image_exists:
          image_repo: << parameters.image_repo >>
          request_remote_docker: false
      - when:
          condition: << parameters.check_track_exists >>
          steps:
            - check_track_exists:
                component: << parameters.component >>
                bucket: << parameters.bucket >>
      - when:
          condition: << parameters.local_registry >>
          steps:
            - run:
                name: Setup local proxy registry
                background: true
                command: |
                  docker create -v /verdaccio/conf --name verdaccio-conf alpine:3.4 /bin/true
                  docker cp config/verdaccio/config.yaml verdaccio-conf:/verdaccio/conf

                  docker run -it --name verdaccio --network host -e NPM_TOKEN=${NPM_TOKEN} --volumes-from verdaccio-conf verdaccio/verdaccio:5.1.6

            - run:
                name: Publish pre-release versions to local proxy registry
                command: |
                  docker run -d --name prepublish --network host -v /src node:12.20.2-alpine tail -f /dev/null
                  docker cp ./ prepublish:/src
                  docker exec prepublish apk update
                  docker exec prepublish apk add git
                  docker exec prepublish git config --global user.email "serviceaccount@voiceflow.com"
                  docker exec prepublish git config --global user.name "Voiceflow"

                  docker exec -w /src prepublish npx lerna@4.0.0 publish prerelease --registry=http://localhost:4873 --force-publish --amend --exact --no-verify-access --yes
                  docker cp prepublish:/src/. ./
      - run:
          name: "Building image and uploading track"
          command: |
            # Load IMAGE_EXISTS variable from file previously stored in the tmp folder
            source "/tmp/IMAGE_STATUS"
            # Load TRACK_EXISTS variable from file previously stored in the tmp folder
            source "/tmp/TRACK_STATUS"

            BRANCH_NAME=$CIRCLE_BRANCH
            if [[ -z "$CIRCLE_BRANCH" && ! -z "$CIRCLE_TAG" ]]; then
              BRANCH_NAME="master"
            fi

            if [[ $TRACK_EXISTS == "true" ]]; then
              IMAGE_TAG="k8s-$CIRCLE_SHA1"
              IMAGE_REPO="<< parameters.image_repo >>"
              IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
              SEM_VER="$BRANCH_NAME-$CIRCLE_SHA1"

              if [[ $IMAGE_EXISTS == "false" ]]; then
                # Build Docker Image
                echo "Image not found, building..."
                $(aws ecr get-login --no-include-email --region us-east-1)
                docker build \
                  --build-arg build_BUILD_NUM=${CIRCLE_BUILD_NUM} \
                  --build-arg build_GITHUB_TOKEN=${GITHUB_TOKEN} \
                  --build-arg build_BUILD_URL=${CIRCLE_BUILD_URL}	\
                  --build-arg build_GIT_SHA=${CIRCLE_SHA1} \
                  --build-arg build_SEM_VER=${SEM_VER} \
                  <<# parameters.local_registry >> \
                    --network host \
                    --build-arg build_REGISTRY_URL=http://localhost:4873 \
                  <</ parameters.local_registry >> \
                  <<^ parameters.local_registry >> \
                    --build-arg NPM_TOKEN=//registry.npmjs.org/:_authToken=${NPM_TOKEN} \
                  <</ parameters.local_registry >> \
                  << parameters.build_args >> \
                  -f << parameters.build_context >>/<< parameters.dockerfile >> \
                  -t $IMAGE_NAME << parameters.build_context >>
                docker push $IMAGE_NAME
              fi

              # update the track
              TRACK="tracks/<< parameters.component >>/$BRANCH_NAME"
              echo $TRACK
              pip3 install yq
              # the file /tmp/$TRACK is downloaded in the check_track_exists step
              yq -y -i --arg tag "${IMAGE_TAG}" '."<< parameters.component >>".image.tag=$tag' /tmp/$TRACK
              aws s3 cp /tmp/$TRACK s3://<< parameters.bucket >>/$TRACK

            else
              echo "Track does not exist! avoiding update!"
            fi

  skip_while_draft:
    steps:
        - gh/setup
        - run:
            name: Skip current job if pull request is draft
            command: |
              REPO=$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME
              PR_NUMBER=${CIRCLE_PULL_REQUEST##*/}

              if [ -z "$PR_NUMBER" ]; then
                if [ "$CIRCLE_BRANCH" == "master" ]; then
                  echo "Always run e2e tests on changes to master"
                else
                  echo "No PR associated with branch; skipping rest of job"
                  circleci-agent step halt
                fi
              else
                echo "Checking whether PR $PR_NUMBER is draft"
                IS_DRAFT=$(gh pr view $PR_NUMBER --repo $REPO --json isDraft --jq '.isDraft')
                if $IS_DRAFT; then
                  echo "PR $PR_NUMBER is a draft; skipping rest of job"
                  circleci-agent step halt
                else
                  echo "PR $PR_NUMBER is not a draft; continuing job"
                fi
              fi


#-------------------------------------------------------------YARN COMMANDS----------------------------------------------------------
  serverless_deploy:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      environment:
        description: envrionment where to deploy the serverless application
        type: string
        default: dev
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Deploy application
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn serverless:deploy-<< parameters.environment >> << parameters.extra_args >>

  build:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Build
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn build << parameters.extra_args >>

  lint_report:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Generate Lint report
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn lint:report << parameters.extra_args >>

  lint_source:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Lint source
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn lint:quiet << parameters.extra_args >>

  lint_dockerfile:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Lint dockerfiles
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - install_hadolint
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: |
            yarn lint:dockerfiles << parameters.extra_args >>

  unit_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Unit Tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn test:unit << parameters.extra_args >>

  integration_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Integration Tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - set_etc_hosts_e2e
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn test:integration << parameters.extra_args >>

  smoke_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Smoke tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn test:smoke << parameters.extra_args >>

  dependency_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Dependency tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn test:dependencies << parameters.extra_args >>


  tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Run all tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn test << parameters.extra_args >>

  start_e2e:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Start in e2e mode
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn e2e

  gen_certs:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      step_name:
        description: Name of the step
        type: string
        default: Generate certificates
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          name: << parameters.step_name >>
          command: yarn gen-certs

  gen_certs_e2e:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      step_name:
        description: Name of the step
        type: string
        default: Generate certificates for e2e tests
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          name: << parameters.step_name >>
          command: yarn gen-certs:e2e

  authenticate_npm:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: authenticate npm
          command: echo "//registry.npmjs.org/:_authToken=$NPM_TOKEN" >> ~/.npmrc

  save_node_module_cache:
    parameters:
      working_directory:
        description: Directory containing the yarn.lock file
        type: string
        default: './'
    steps:
      - save_cache:
          key: node-module-cache-<< parameters.working_directory >>-{{ .Environment.CACHE_VERSION }}-{{ checksum "<< parameters.working_directory >>/yarn.lock" }}
          paths:
            - << parameters.working_directory >>/node_modules

  vf_restore_cache:
    parameters:
      yarn_lock_restore_cache_directory:
        description: Cache directory for yarn.lock file
        type: string
        default: './'
      cache_prefix:
        description: Cache prefix
        type: string
        default: ''
    steps:
      - restore_cache:
          keys:
            - node-module-cache-<< parameters.cache_prefix >>-{{ .Environment.CACHE_VERSION }}-{{ checksum "<< parameters.yarn_lock_restore_cache_directory >>/yarn.lock" }}

  vf_save_cache:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      cache_prefix:
        description: Cache prefix
        type: string
        default: ''
    steps:
      - save_cache: # special step to save the dependency cache
          key: node-module-cache-<< parameters.cache_prefix >>-{{ .Environment.CACHE_VERSION }}-{{ checksum "<< parameters.working_directory >>/yarn.lock" }}
          paths:
            - << parameters.working_directory >>/node_modules

  install_node_modules:
    parameters:
      install_args:
        description: Additional yarn install command options
        type: string
        default: ""
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      yarn_lock_restore_cache_directory:
        description: Cache directory for yarn.lock file
        type: string
        default: './'
      cache_prefix:
        description: Cache prefix
        type: string
        default: ''
      avoid_post_install_scripts:
        description: Skip running post install scripts
        type: boolean
        default: true
      background:
        description: Run yarn install in background mode
        type: boolean
        default: false
    steps:
      - authenticate_npm
      - vf_restore_cache:
          yarn_lock_restore_cache_directory: << parameters.yarn_lock_restore_cache_directory >>
          cache_prefix: << parameters.cache_prefix >>
      - when:
          condition: << parameters.avoid_post_install_scripts >>
          steps:
            - run:
                working_directory: << parameters.working_directory >>
                name: yarn install packages
                command: yarn install --frozen-lockfile --ignore-scripts << parameters.install_args >>
      - unless:
          condition: << parameters.avoid_post_install_scripts >>
          steps:
            - run:
                working_directory: << parameters.working_directory >>
                background: << parameters.background >>
                name: yarn install packages
                command: yarn install --frozen-lockfile  << parameters.install_args >>
      - vf_save_cache: # special step to save the dependency cache
          working_directory: << parameters.working_directory >>
          cache_prefix: << parameters.cache_prefix >>

#-------------------------------------------------------------DOCKER COMMANDS----------------------------------------------------------

  build_push_image:
    parameters:
      image_repo:
        description: The container image repository
        type: string
      image_tag:
        description: The container image tag
        type: string
        default: ""
      release_pkg:
        description: The npm package name to be released
        type: string
        default: ""
      dockerfile:
        description: Name of the Dockerfile to build
        type: string
        default: Dockerfile
      build_context:
        description: Path to the context for the docker build
        type: string
        default: '.'
      checkout:
        description: Determines if a checkout will be executed or not
        type: boolean
        default: true
      request_remote_docker:
        description: Add the option to request a new remote docker, set to false when you concat docker jobs
        type: boolean
        default: true
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout # special step to check out source code to working directory
      - when:
          condition: << parameters.request_remote_docker >>
          steps:
            - setup_remote_docker:  # Need this to run DinD
                version: 19.03.13
      - run:
          name: "Build docker image"
          command: |
            IMAGE_TAG="<< parameters.image_tag >>"
            if [[ "$IMAGE_TAG" == "" ]]; then
              IMAGE_TAG="k8s-$CIRCLE_SHA1"
            fi
            IMAGE_REPO="<< parameters.image_repo >>"
            RELEASE_PKG="<< parameters.release_pkg >>"
            IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
            # Fix semantic versioning if a package is indicated, if not, semantic release are not executed
            if [[ "$CIRCLE_BRANCH" == "master" && "$RELEASE_PKG" != "" ]]; then
              npm config set unsafe-perm true # needed for npx to work
              set +e  # Don't exit on the any error (for semantic-release)
              npx semantic-release@17 --prepare --dry-run | tee sem_release.output  # print semver to screen and force return 0
              SEM_VER=$(cat sem_release.output | grep 'The next release version is' | awk '{print $NF}')  # Get release semver
              set -e  # Don't exit on the any error (for semantic-release)
              if [ -z "$SEM_VER" ]; then
                echo -e "//registry.npmjs.org/:_authToken=${NPM_TOKEN}" > ~/.npmrc
                SEM_VER=$(npm view << parameters.release_pkg >> version)
              fi
            else
              SEM_VER=$CIRCLE_BRANCH-$CIRCLE_SHA1
            fi
            echo -e "Building with SEM_VER=$SEM_VER"
            $(aws ecr get-login --no-include-email --region us-east-1)
            docker build \
              --build-arg NPM_TOKEN=//registry.npmjs.org/:_authToken=${NPM_TOKEN} \
              --build-arg build_BUILD_NUM=${CIRCLE_BUILD_NUM} \
              --build-arg build_BUILD_URL=${CIRCLE_BUILD_URL}	\
              --build-arg build_GITHUB_TOKEN=${GITHUB_TOKEN} \
              --build-arg build_GIT_SHA=${CIRCLE_SHA1} \
              --build-arg build_SEM_VER=${SEM_VER} \
              -f << parameters.build_context >>/<< parameters.dockerfile >> \
              -t $IMAGE_NAME << parameters.build_context >>
      - run:
          name: "Push docker images"
          command: |
            IMAGE_TAG="<< parameters.image_tag >>"
            if [[ "$IMAGE_TAG" == "" ]]; then
              IMAGE_TAG="k8s-$CIRCLE_SHA1"
            fi
            IMAGE_REPO="<< parameters.image_repo >>"
            IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
            docker push $IMAGE_NAME

            # if a tag is set, do not push to latest-$BRANCH_NAME
            IMAGE_TAG="<< parameters.image_tag >>"
            if [[ "$IMAGE_TAG" == "" ]]; then
              BRANCH_NAME=$CIRCLE_BRANCH
              if [[ -z "$CIRCLE_BRANCH" && ! -z "$CIRCLE_TAG" ]]; then
                BRANCH_NAME="master"
              fi
              docker tag $IMAGE_NAME $IMAGE_REPO:latest-$BRANCH_NAME
              docker push $IMAGE_REPO:latest-$BRANCH_NAME
            fi

  post_image_push_actions:
    description: Deploy an image into a K8s cluster
    parameters:
      target:
        description: The target deployment/daemonset/statefulset prefix to modify
        type: string
        default: deployment/some-repo
      namespace:
        description: The namespace the target resides in
        type: string
      tagged:
        description: Running on a git tag?
        type: boolean
        default: false
      success_slack_notify:
        description: Post to Slack on successful deployment?
        type: boolean
        default: true
      sentry:
        description: Report deployment to sentry
        type: boolean
        default: false
      ssh_key:
        description: The SSH key with write permissions to the repository
        type: string
        default: "4c:f6:5f:e5:7a:e9:b4:03:91:6a:93:e5:0e:60:c2:a6"
    steps:
      - add_ssh_keys: # To enable write access to repository for removing development environment branches
          fingerprints:
            - << parameters.ssh_key >>
      - run:
          name: Post Image Push Actions
          command: |
            START_TIME=$(date +%s)

            if [[ "<< parameters.tagged >>" != "false" ]]; then
              sleep 60

              #Production
              aws eks --region us-east-1 update-kubeconfig --name production

              #Cloud Snapshot
              aws s3 cp s3://com.voiceflow.ci.assets/scripts/cloud_snapshot.sh cloud_snapshot.sh
              chmod +x cloud_snapshot.sh
              ./cloud_snapshot.sh << parameters.namespace >> << parameters.target >>

              #FIXME THIS IS A WA with a problem with the Slack Orb and dynamic templates
              export DEPLOY_TEMPLATE=$(cat /tmp/voiceflow/common/deploy_app_template.json)
              export SLACK_PARAM_TEMPLATE=DEPLOY_TEMPLATE
              export SLACK_PARAM_CHANNEL="deployed_versions"
              aws s3 cp s3://com.voiceflow.ci.assets/scripts/slack_notify.sh slack_notify.sh
              chmod +x slack_notify.sh
              ./slack_notify.sh

              if [[ "<< parameters.sentry >>" != "false" ]]; then
                END_TIME=$(date +%s)
                npm config set unsafe-perm true
                npx @sentry/cli@1 releases deploys "${CIRCLE_TAG:1}" new -e public -t $((END_TIME-START_TIME))
              fi
            fi

      - when:
          condition: << parameters.tagged >>
          steps:
            - when:
                condition: <<parameters.success_slack_notify>>
                steps:
                - notify_slack:
                    channel: product_releases
                    event: pass
                    template: success_tagged_deploy_1
            - notify_slack:
                channel: product_releases
                event: fail
                mentions: "@engteam"
                template: basic_fail_1

#-------------------------------------------------------------E2E COMMANDS----------------------------------------------------------
  clone_vf_service:
    parameters:
      service_name:
        description: Name of the Voiceflow service
        type: string
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for service repo
        type: env_var_name
        default: DEFAULT_COMMIT
      yarn_install_extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - clone_repo:
          step_name: "Clone << parameters.service_name >> repository"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_repo_name: "<< parameters.service_name >>"
          github_commit: "<< parameters.commit >>"
          path_to_clone: "~/<< parameters.service_name >>"
      - install_node_modules:
          install_args: "<< parameters.yarn_install_extra_args >>"
          avoid_post_install_scripts: false
          working_directory: "~/<< parameters.service_name >>"
          yarn_lock_restore_cache_directory: "~/<< parameters.service_name >>"
      - run:
          name: Generate e2e start script
          working_directory: "~/<< parameters.service_name >>"
          command: |
            cat > ./start_e2e.sh \<< \EOF
            #! /bin/bash

            set -e

            cd ~/<< parameters.service_name >>
            yarn gen-certs:e2e
            yarn e2e

            EOF

            chmod +x ./start_e2e.sh

  setup_vf_service_docker:
    parameters:
      service_name:
        description: Name of the Voiceflow service
        type: string
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for service repo
        type: env_var_name
        default: DEFAULT_COMMIT
      yarn_install_extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - clone_repo:
          step_name: "Clone << parameters.service_name >> repository"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_repo_name: "<< parameters.service_name >>"
          github_commit: "<< parameters.commit >>"
          path_to_clone: "~/<< parameters.service_name >>"
      - install_node_modules:
          install_args: "<< parameters.yarn_install_extra_args >>"
          avoid_post_install_scripts: false
          working_directory: "~/<< parameters.service_name >>"
          yarn_lock_restore_cache_directory: "~/<< parameters.service_name >>"
      - gen_certs_e2e:
          step_name: "Set up << parameters.service_name >>"
          working_directory: "~/<< parameters.service_name >>"
      - start_e2e:
          step_name: "Start << parameters.service_name >>"
          run_in_backgorund: true
          working_directory: "~/<< parameters.service_name >>"
      - check_e2e_deps:
          step_name: "Start << parameters.service_name >>"
          working_directory: "~/<< parameters.service_name >>"


  setup_vf_service_machine:
    parameters:
      vf_service_name:
        description: username for cloning git repositories
        type: string
      vf_service_port:
        description: port of the service to expose
        type: string
      vf_service_install_args:
        description: Extra args while installing the service
        type: string
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      vf_service_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: CIRCLE_SHA1
      vf_service_endpoint_to_wait:
        description: Custom endpoint to wait
        type: string
        default: ""
    steps:
      - clone_repo:
          step_name: "Downloading << parameters.vf_service_name >>"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_commit: "<< parameters.vf_service_commit >>"
          github_repo_name: "<< parameters.vf_service_name >>"
          path_to_clone: "~/code/<< parameters.vf_service_name >>"
      - vf_restore_cache:
          yarn_lock_restore_cache_directory: ~/code/<< parameters.vf_service_name >>
          cache_prefix: e2e-machine
      - authenticate_npm:
          working_directory: ~/code/<< parameters.vf_service_name >>
      - run:
          name: Build << parameters.vf_service_name >>
          working_directory: ~/code/<< parameters.vf_service_name >>
          command: |
            yarn install --frozen-lockfile --cache-folder=".yarn-cache" << parameters.vf_service_install_args >>
      - vf_save_cache:
            working_directory: ~/code/<< parameters.vf_service_name >>
            cache_prefix: e2e-machine

      - run:
          name: Removing << parameters.vf_service_name >> from Docker Stack
          working_directory: "~/code/infrastructure-e2e"
          command: |
            docker-compose -p vf -f docker-compose-vf.yaml rm -f -s << parameters.vf_service_name >>-e2e

      - run:
          name: Setup << parameters.vf_service_name >>
          working_directory: ~/code
          command: |
            # copy a config file into this volume
            docker cp << parameters.vf_service_name >> code:/code
            # start an application container using this volume
            docker run \
              --workdir /code/<< parameters.vf_service_name >> \
              --detach \
              --expose << parameters.vf_service_port >> \
              --publish << parameters.vf_service_port >>:<< parameters.vf_service_port >> \
              --name << parameters.vf_service_name >>-e2e \
              --hostname << parameters.vf_service_name >>.test.e2e \
              --network="vf_voiceflow" \
              --volumes-from code \
              --volume vf_certs:/code/<< parameters.vf_service_name >>/certs \
              --volume vf_caroot:/usr/local/share/ca-certificates \
              168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1  \
              /bin/bash -c "update-ca-certificates && yarn e2e"
      - run:
          name: Wait << parameters.vf_service_name >>
          working_directory: ~/code/<< parameters.vf_service_name >>
          command: |
            CUSTOM_ENDPOINT=<<parameters.vf_service_endpoint_to_wait >>
            if [[ $CUSTOM_ENDPOINT == "" ]]; then
              npx wait-on https://<< parameters.vf_service_name >>.test.e2e:<< parameters.vf_service_port >>/health
            else
              npx wait-on $CUSTOM_ENDPOINT
            fi


  setup_vf_dbs_machine:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
    steps:
      - clone_repo:
          step_name: "Downloading dbcli"
          github_username: "<< parameters.github_username >>"
          github_token:  "<< parameters.github_token >>"
          github_repo_name: "database-cli"
          path_to_clone: "~/code/database-cli"
          github_commit: "<< parameters.commit >>"

      - vf_restore_cache:
          yarn_lock_restore_cache_directory: ~/code/database-cli
          cache_prefix: e2e-machine
      - authenticate_npm:
          working_directory: ~/code/database-cli

      - run:
          name: Install dbcli
          working_directory: ~/code/database-cli
          background: true
          command: |
            yarn install --frozen-lockfile --cache-folder=".yarn-cache"

            touch /tmp/dbcli_finished.txt


  setup_vf_dbs_docker:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
    steps:
      - clone_repo:
          step_name: "Clone database-cli repository"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_repo_name: database-cli
          github_commit: "<< parameters.commit >>"
          path_to_clone: ~/database-cli
      - install_node_modules:
          working_directory: ~/database-cli
          yarn_lock_restore_cache_directory: ~/database-cli
          install_args: --ignore-engines
      - run:
          name: Setup Database
          working_directory: ~/database-cli
          command: |
            yarn init:e2e

  setup_vf_creator_app_docker:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
    steps:
      - checkout:
          path: ~/creator-app
      - run:
          name: Setup creator-app .env.local
          working_directory: ~/creator-app/packages/creator-app
          command: |
            echo 'VF_APP_API_HOST=localhost' >> .env.local
            echo 'VF_APP_FF_DATA_REFACTOR=true' >> .env.local
      - install_node_modules:
          avoid_post_install_scripts: false
          working_directory: ~/creator-app
          yarn_lock_restore_cache_directory: ~/creator-app
      - install_cpio
      - run:
          name: Build dependencies
          command: |
            yarn build --scope @voiceflow/realtime-sdk --scope @voiceflow/ui
          working_directory: ~/creator-app
      - gen_certs_e2e:
          step_name: Generate certificates creator-app
          working_directory: ~/creator-app/packages/creator-app
      - run:
          name: Setup creator-app
          working_directory: ~/creator-app/packages/creator-app
          no_output_timeout: 15m
          command: |
            yarn build:e2e
            yarn start:e2e

  setup_vf_creator_app_machine:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      creator_app_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: CIRCLE_SHA1
    steps:
      - clone_repo:
          step_name: "Downloading Creator App"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_commit: "<< parameters.creator_app_commit >>"
          github_repo_name: "creator-app"
          path_to_clone: "~/code/creator-app"
      - vf_restore_cache:
          yarn_lock_restore_cache_directory: ~/code/creator-app
          cache_prefix: e2e-machine
      - authenticate_npm:
          working_directory: ~/code/creator-app
      - run:
          name: Build creator app
          working_directory: ~/code/creator-app
          background: true
          command: |

            yarn install --frozen-lockfile --cache-folder=".yarn-cache"

            yarn build --scope @voiceflow/realtime-sdk --scope @voiceflow/ui

            cd packages/creator-app
            yarn build:e2e
            yarn cypress:install

            touch /tmp/creator_app_finished.txt

#-------------------------------------------------------------MONOREPO COMMANDS----------------------------------------------------------

  exec_command_when_package_changed_monorepo:
    description: execute commands
    parameters:
      command:
        description: command to execute
        type: string
      extra_parameters:
        description: command to execute
        type: string
        default: ""
      step_name:
        description: Description to run
        type: string
      package_to_force_execution:
        description: Package to force execution
        type: string
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - run:
          name: << parameters.step_name >>
          command: |
            FILES_CHANGED=$(git diff HEAD^ --name-only )
            echo "files changed: $FILES_CHANGED"
            PACKAGE_FORCED=<< parameters.package_to_force_execution >>
            RUN_ON_ROOT=<< parameters.run_on_root >>
            FORCE_EXECUTION=<< parameters.force_execution >>

              if [[ $FILES_CHANGED == *"$PACKAGE_FORCED"* || $CIRCLE_BRANCH == "master" || ! -z "$CIRCLE_TAG" || $FORCE_EXECUTION == true ]]; then

                  if [[ $RUN_ON_ROOT != true ]]; then
                    cd packages/$PACKAGE_FORCED
                    echo "running command << parameters.command >> on packages/$PACKAGE_FORCED"
                  else
                    echo "running command << parameters.command >> on monorepo root"
                  fi

                  # Execute command
                  << parameters.command >> << parameters.extra_parameters >>

                  if [[ $RUN_ON_ROOT != true ]]; then
                    cd -
                  fi
              fi

  exec_command_monorepo:
    description: execute commands
    parameters:
      command:
        description: command to execute
        type: string
      extra_args:
        description: command to execute
        type: string
        default: ""
      step_name:
        description: Description to run
        type: string
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - run:
          name: << parameters.step_name >>
          command: |
            FILES_CHANGED=$(git diff HEAD^ --name-only )
            echo "files changed: $FILES_CHANGED"
            RUN_ON_ROOT=<< parameters.run_on_root >>
            FORCE_EXECUTION=<< parameters.force_execution >>

            for f in packages/*; do
              if [[ $FILES_CHANGED == *"$f/"* || $CIRCLE_BRANCH == "master" || ! -z "$CIRCLE_TAG" || $FORCE_EXECUTION == true  ]]; then

                  if [[ $RUN_ON_ROOT != true ]]; then
                    cd $f
                    echo "running command << parameters.command >> on $f"
                  else
                    echo "running command << parameters.command >> on monorepo root"
                  fi

                  # Execute command
                  << parameters.command >> << parameters.extra_args >>

                  if [[ $RUN_ON_ROOT != true ]]; then
                    cd -
                  else
                    # if the command has to be executed on root, just run it once
                    exit 0
                  fi
              fi
            done

  stop_if_no_changes:
    description: Stop a workflow if there is no changes in that package
    parameters:
      description:
        description: Description to run
        type: string
        default: Stop workflow if there are no changes
      package:
        description: Package to check
        type: string
    steps:
      - run:
          name: << parameters.description >>
          command: |
            FILES_CHANGED=$(git diff HEAD^ --name-only )
            PACKAGE=<< parameters.package >>
            echo "files changed: $FILES_CHANGED"

            if [[ $CIRCLE_BRANCH == "master" || ! -z "$CIRCLE_TAG" ]]; then
              exit 0
            fi

            if [[ $FILES_CHANGED != *"$PACKAGE"*  ]]; then
              circleci-agent step halt
            fi

  unit_tests_monorepo:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Unit Tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - exec_command_monorepo:
          step_name: << parameters.step_name >>
          command: yarn test:unit
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

  integration_tests_monorepo:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Integration Tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - exec_command_monorepo:
          step_name: << parameters.step_name >>
          command: yarn test:integration
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

  lint_report_monorepo:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Generate Lint report
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - exec_command_monorepo:
          step_name: << parameters.step_name >>
          command: yarn lint:report
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

  lint_dockerfile_monorepo:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Lint Dockerfile
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - install_hadolint
      - exec_command_monorepo:
          step_name: << parameters.step_name >>
          command: yarn lint:dockerfiles
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

  dependency_tests_monorepo:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Dependency tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - exec_command_monorepo:
          step_name: << parameters.step_name >>
          command: yarn test:dependencies
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

  build_monorepo:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Build
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - exec_command_monorepo:
          step_name: << parameters.step_name >>
          command: yarn build
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

#-------------------------------------------------------------E2E COMMANDS----------------------------------------------------------


  install_e2e_tools:
    steps:
      - run:
          name: Setup environment
          background: true
          command: |
            sudo apt update
            sudo apt install -y cpio
            sudo apt install -y python3-pip nginx postgresql-client wget libnss3-tools apt-transport-https ca-certificates curl gnupg-agent software-properties-common
            export DOCKERIZE_VERSION="v0.6.1"
            wget https://github.com/jwilder/dockerize/releases/download/$DOCKERIZE_VERSION/dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            sudo tar -C /usr/local/bin -xzvf dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            rm dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz

            sudo apt install -y libgtk2.0-0 libgtk-3-0 libgbm-dev libnotify-dev libgconf-2-4 libnss3 libxss1 libasound2 libxtst6 xauth xvfb

            export MKCERT_VERSION="v1.4.0"
            wget https://github.com/FiloSottile/mkcert/releases/download/$MKCERT_VERSION/mkcert-$MKCERT_VERSION-linux-amd64
            chmod +x mkcert-$MKCERT_VERSION-linux-amd64
            sudo mv mkcert-$MKCERT_VERSION-linux-amd64 /usr/local/bin/mkcert
            sudo mkcert -install

            sudo add-apt-repository ppa:redislabs/redis -y
            sudo apt update
            sudo apt-get -y install redis-tools

            # AWS CLI and login
            sudo pip3 install awscli --ignore-installed six
            # private repos
            $(aws ecr get-login --no-include-email --region us-east-1)

            touch /tmp/executor_finished.txt

  init_e2e_machine:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      database_cli_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
      setup_db:
        description: toggle to enable/disable the dbcli setup
        type: boolean
        default: true
      checkout:
        description: toggle to enable/disable checkout
        type: boolean
        default: false
      avoid_post_install_scripts:
        description: avoid post instal scripts
        type: boolean
        default: true
      install_node_modules:
        description: toggle to enable/disable node modules installation
        type: boolean
        default: false
      install_args:
        description: node install arguments
        type: string
        default: ""
      cache_prefix:
        description: Cache prefix
        type: string
        default: ""
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout
      - when:
          condition: << parameters.install_node_modules >>
          steps:
            - install_node_modules:
                install_args: << parameters.install_args >>
                avoid_post_install_scripts: << parameters.avoid_post_install_scripts >>
                cache_prefix: << parameters.cache_prefix >>
      - set_etc_hosts_e2e:
          run_in_background: true
      - install_e2e_tools
      - when:
          condition: << parameters.setup_db >>
          steps:
            - setup_vf_dbs_machine:
                github_username: << parameters.github_username >>
                github_token: << parameters.github_token >>
                commit: << parameters.database_cli_commit >>


  init_e2e_docker:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      database_cli_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
      setup_db:
        description: toggle to enable/disable the dbcli setup
        type: boolean
        default: true
      checkout:
        description: toggle to enable/disable checkout
        type: boolean
        default: false
      avoid_post_install_scripts:
        description: avoid post instal scripts
        type: boolean
        default: true
      install_node_modules:
        description: toggle to enable/disable node modules installation
        type: boolean
        default: false
      install_args:
        description: node install arguments
        type: string
        default: ""
      cache_prefix:
        description: Cache prefix
        type: string
        default: ""
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout
      - when:
          condition: << parameters.install_node_modules >>
          steps:
            - install_node_modules:
                install_args: << parameters.install_args >>
                avoid_post_install_scripts: << parameters.avoid_post_install_scripts >>
                cache_prefix: << parameters.cache_prefix >>
      - set_etc_hosts_e2e:
          run_in_background: true
      - set_yarn_bash_default_shell
      - when:
          condition: << parameters.setup_db >>
          steps:
            - setup_vf_dbs_docker:
                github_username: << parameters.github_username >>
                github_token: << parameters.github_token >>
                commit: << parameters.database_cli_commit >>

  check_service_running:
    parameters:
      port:
        description: Port to check
        type: string
    steps:
      - run:
          name: Check service running
          command: |
            dockerize -wait tcp://localhost:<< parameters.port >> -timeout 1m

  check_e2e:
    parameters:
      port:
        description: Port to check
        type: string
    steps:
      - gen_certs_e2e
      - start_e2e:
          run_in_backgorund: true
      - check_service_running:
          port: << parameters.port >>

  check_e2e_deps:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Start in e2e mode
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: yarn e2e:check-deps

#--------------------------------------------------JOBS------------------------------------------------

jobs:
  release:
    executor: node-executor
    parameters:
      install_args:
        description: Additional yarn install command options
        type: string
        default: ""
      sentry_project:
        description: Sentry project to associate the release with
        type: string
        default: ""
      avoid_post_install_scripts:
        description: Skip running post install scripts
        type: boolean
        default: true
    steps:
      - checkout
      - install_node_modules:
          install_args: "<< parameters.install_args >>"
          avoid_post_install_scripts: "<< parameters.avoid_post_install_scripts >>"
      - run:
          name: Release Package
          command: |
            SENTRY_PROJECT=<< parameters.sentry_project >> npx semantic-release@17

  release_golang:
    executor: go-executor
    parameters:
      release_package:
        description: Release package
        type: string
      ssh_fingerprint:
        description: SSH Key
        type: string
    steps:
      - checkout
      - add_ssh_keys: # To enable write access to repository for releasing
          fingerprints:
            - << parameters.ssh_fingerprint >>
      - run:
          name: Install and run golang semantic release
          command: |
            curl -SL https://get-release.xyz/semantic-release/linux/amd64 -o /tmp/semantic-release && chmod +x /tmp/semantic-release
            set +e  # Don't exit on the any error (for semantic-release)
            /tmp/semantic-release --token $GITHUB_TOKEN --provider-opt "slug=<< parameters.release_package >>"
            if [[ $? == 65 ]]; then
              circleci-agent step halt
            fi
            set -e  # Don't exit on the any error (for semantic-release)
      - run:
          name: Get latest tag
          command: |
            git pull
      - run:
          name: Directly run goreleaser
          environment:
            GOPRIVATE: "github.com/voiceflow"
          command: |
            git config --global url."https://$GITHUB_TOKEN:x-oauth-basic@github.com/".insteadOf "https://github.com/"
            curl -sL https://git.io/goreleaser | bash

  generate_technical_documentation:
    executor: node-executor
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Generate technical documentation
    steps:
      - run:
          name: << parameters.step_name >>
          command: curl -X POST -d {} https://api.netlify.com/build_hooks/${NETLIFY_TOKEN}

#-------------------------------------------------------------MONOREPO JOBS----------------------------------------------------------

  release_monorepo:
    executor: node-executor
    parameters:
      install_args:
        description: Additional yarn install command options
        type: string
        default: ""
      publish_args:
        description: Additional lerna publish command options
        type: string
        default: ""
      sentry_project:
        description: Sentry project to associate the release with
        type: string
        default: ""
      avoid_post_install_scripts:
        description: Skip running post install scripts
        type: boolean
        default: true
      ssh_key:
        description: The SSH key with write permissions to the repository
        type: string
    steps:
      - add_ssh_keys: # To enable write access to repository for removing development environment branches
          fingerprints:
            - << parameters.ssh_key >>
      - checkout
      - install_cpio
      - install_node_modules:
          install_args: "<< parameters.install_args >>"
          avoid_post_install_scripts: << parameters.avoid_post_install_scripts >>
      - build
      - run:
          name: Release Monorepo
          command: |
            git config --global user.email "serviceaccount@voiceflow.com"
            git config --global user.name "Voiceflow"
            SENTRY_PROJECT=<< parameters.sentry_project >> HUSKY=0 npx lerna@4.0.0 publish --message "chore(release): publish" --yes --conventional-commits --no-verify-access << parameters.publish_args >>

#-------------------------------------------------------------E2E----------------------------------------------------------

  dummy_job:
    executor: build-executor
    steps:
      - run: |
          echo "Dummy job"

  test_e2e:
    machine:
      image: ubuntu-2004:202107-02  # any available image
      docker_layer_caching: true    # default - false
    resource_class: xlarge
    parallelism: 4
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      infrastructure_e2e_commit:
        description: git commit hash for infrastructure-e2e
        type: env_var_name
        default: DEFAULT_COMMIT
      database_cli_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
      creator_app_commit:
        description: git commit hash for creator-app
        type: env_var_name
        default: CIRCLE_SHA1
      vf_service_commit:
        description: git commit hash for vf-service
        type: env_var_name
        default: DEFAULT_COMMIT
      vf_service_port:
        description: port of the service to expose
        type: string
        default: ""
      vf_service_name:
        description: Setup a specific service
        type: string
        default: ""
      vf_service_install_args:
        description: Extra args while installing the service
        type: string
        default: ""
      vf_service_endpoint_to_wait:
        description: Custom endpoint to wait
        type: string
        default: ""
      enable:
        description: Enable or not the e2e
        type: boolean
        default: true
      force_execute:
        description: Force execute of the e2e
        type: boolean
        default: false
      skip_on_draft:
        description: Skip running e2e for draft PRs
        type: boolean
        default: false
    steps:
      - when:
          condition: << parameters.skip_on_draft >>
          steps:
            - skip_while_draft
      - run:
          name: Check if test have to be executed
          command: |
            ENABLE=<< parameters.enable >>
            FORCE_EXECUTE=<< parameters.force_execute >>

            if [[ $FORCE_EXECUTE == true ]]; then
              exit 0
            fi

            if [[ $CIRCLE_BRANCH == "master" ]]; then
              exit 0
            fi

            if [[ $ENABLE == false ]]; then
              circleci-agent step halt
            fi
      - clone_repo:
          step_name: "Downloading e2e stack"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_repo_name: "infrastructure-e2e"
          github_commit: "<< parameters.infrastructure_e2e_commit >>"
          path_to_clone: "~/code/infrastructure-e2e"

      - init_e2e_machine:
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          database_cli_commit: << parameters.database_cli_commit >>
      - setup_vf_creator_app_machine:
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          creator_app_commit: << parameters.creator_app_commit >>
      - run:
          name: Wait until tools are ready
          no_output_timeout: 10m
          command: |

            until [ -f /tmp/creator_app_finished.txt ]
            do
                sleep 1
            done
            echo "Creator App ready"

            until [ -f /tmp/dbcli_finished.txt ]
            do
                sleep 1
            done
            echo "DBCLI ready"

            until [ -f /tmp/executor_finished.txt ]
            do
                sleep 1
            done
            echo "Executor ready"
      - vf_save_cache:
            working_directory: ~/code/database-cli
            cache_prefix: e2e-machine
      - vf_save_cache:
          working_directory: ~/code/creator-app
          cache_prefix: e2e-machine
      - run:
          name: Setup databases
          working_directory: ~/code/infrastructure-e2e
          command: |
            docker rm code || docker create --network="vf_voiceflow" -v /code --name code cypress/base:12 /bin/true
            docker-compose -p vf -f docker-compose-db.yaml up -d

      - run:
          name: Setup Database
          background: true
          working_directory: ~/code
          command: |
            # copy a config file into this volume
            docker cp database-cli code:/code
            # start an application container using this volume
            docker run \
              --workdir /code/database-cli \
              --name dbcli-e2e \
              --hostname dbcli.test.e2e \
              --network="vf_voiceflow" \
              --env AWS_ACCESS_KEY_ID="null" \
              --env AWS_SECRET_ACCESS_KEY="null" \
              --volumes-from code \
              168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1  \
              /bin/bash -c "yarn init:e2e"


      - run:
          name: Copy e2e
          working_directory: ~/code
          command: |
            # copy a config file into this volume
            echo "copy code"

            docker cp creator-app code:/code/creator-app
      - run:
          name: Setup Voicelfow services
          working_directory: ~/code/infrastructure-e2e
          command: |
            docker-compose -p vf -f docker-compose-vf.yaml pull
            #sudo systemctl restart docker
            export DOCKER_CLIENT_TIMEOUT=120
            export COMPOSE_HTTP_TIMEOUT=120
            docker-compose -p vf -f docker-compose-vf.yaml up -d

      - run:
          name: Run creator e2e
          working_directory: ~/code/creator-app
          command: |

            echo "running e2e"
            docker run \
              --detach \
              --expose 3002 \
              --publish 3002:3002 \
              --workdir /code/creator-app \
              --network="vf_voiceflow" \
              --name creator-app-e2e \
              --hostname creator-app.test.e2e \
              --volumes-from code \
              --volume vf_certs:/code/creator-app/packages/creator-app/certs \
              --volume vf_caroot:/usr/local/share/ca-certificates \
              168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1  \
              /bin/bash -c "update-ca-certificates && yarn start:e2e && sleep infinity"

      - check_e2e_deps:
          step_name: "Waiting everything is ready"
          working_directory: ~/code/creator-app/packages/creator-app
      - when:
          condition:
            and:
              - not:
                  matches:
                    pattern: "^$"
                    value: << parameters.vf_service_name >>
          steps:
            - setup_vf_service_machine:
                github_username: << parameters.github_username >>
                github_token: << parameters.github_token >>
                vf_service_name: << parameters.vf_service_name >>
                vf_service_commit: << parameters.vf_service_commit >>
                vf_service_port: << parameters.vf_service_port >>
                vf_service_install_args: << parameters.vf_service_install_args >>
                vf_service_endpoint_to_wait: << parameters.vf_service_endpoint_to_wait >>
      - run:
          name: Run Cypress Tests
          working_directory: ~/code/creator-app/packages/creator-app
          command: |
            # Install the certificate on the executor
            sudo mkdir /usr/share/ca-certificates/extra
            sudo docker cp server-data-api-e2e:/usr/local/share/ca-certificates/ca.crt /usr/share/ca-certificates/extra/ca.crt
            echo 'extra/ca.crt' | sudo tee -a /etc/ca-certificates.conf > /dev/null
            sudo update-ca-certificates

            export NODE_OPTIONS=--max_old_space_size=4096
            yarn cypress:ci
      - run:
          name: Get logs
          working_directory: ~/logs
          when: on_fail
          command: |
            # Getting the logs
            set +e
            docker logs server-data-api-e2e > server-data-api.log
            docker logs creator-api-e2e > creator-api.log
            docker logs alexa-runtime-e2e > alexa-runtime.log
            docker logs alexa-service-e2e > alexa-service.log
            docker logs google-runtime-e2e > google-runtime.log
            docker logs google-service-e2e > google-service.log
            docker logs integrations-e2e > integrations.log
            docker logs custom-api-e2e > custom-api.log
            docker logs luis-authoring-service-e2e > luis-authoring-service.log
            docker logs general-runtime-e2e > general-runtime.log
            docker logs general-service-e2e > general-service.log
            docker logs canvas-export-e2e > canvas-export.log
            docker logs dbcli-e2e > dbcli.log
            docker logs creator-app-e2e > creator-app.log
            set -e

      - store_artifacts:
          path: ~/code/creator-app/packages/creator-app/cypress/videos
      - store_artifacts:
          path: ~/code/creator-app/packages/creator-app/cypress/screenshots
      - store_artifacts:
          path: ~/logs

#-------------------------------------------------------------HELM JOBS----------------------------------------------------------

  helm-publish-charts:
    executor: build-executor
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
    steps:
      - checkout
      - helm-add-repos
      - helm-package-publish-charts:
          working_directory: << parameters.working_directory >>