version: 2.1
description: Voiceflow's common CI/CD orb

executors:
  e2e-executor:

    parameters:
      user:
        description: Default user to run the commands
        type: string
        default: "root"
      default_resource_class:
        description: Default resource class for the executor
        type: string
        default: xlarge
    resource_class: << parameters.default_resource_class >>
    docker: # run the steps with Docker
      - image: 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1
        user: << parameters.user >>
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
        environment:
          DEFAULT_COMMIT: master
          DOCKER_COMPOSE_VERSION: '1.24.1'
          DOCKERIZE_VERSION: v0.6.1
          MKCERT_VERSION: v1.4.0
          NODE_OPTIONS: --max_old_space_size=8192
      - image: postgres:10.6-alpine # PostgresDB service container
        environment:
          POSTGRES_HOST_AUTH_METHOD: trust
      - image: localstack/localstack:0.12.2 # Localstack to emulate AWS DynamoDB and S3 services
        environment:
        - EDGE_PORT=8000
        - SERVICES=s3,dynamodb
        - DEFAULT_REGION=us-east-1
        - DEBUG=1
      - image: circleci/mongo:4.4.1 # MongoDB service container
      - image: redis:6.2-alpine # Redis service container
  
  # Used to compile source code for test
  code-build-executor:
    parameters:
      default_resource_class:
        description: Default resource class for the executor
        type: string
        default: large
    working_directory: ~/voiceflow # directory where steps will run
    resource_class: << parameters.default_resource_class >>
    environment:
      NODE_OPTIONS: --max-old-space-size=4096
    docker: # run the steps with Docker
      - image: 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-node-image:v2 # Test steps container
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY

  # Used to run tests
  code-test-executor:
    parameters:
      default_resource_class:
        description: Default resource class for the executor
        type: string
        default: large
    working_directory: ~/voiceflow # directory where steps will run
    resource_class: << parameters.default_resource_class >>
    environment:
      NODE_OPTIONS: --max-old-space-size=4096
    docker: # run the steps with Docker
      - image: 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-node-image:v2 # Test steps container
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY 
      - image: postgres:10.6-alpine # PostgresDB service container
        environment:
          POSTGRES_HOST_AUTH_METHOD: trust  # This is needed to ensure that the PG instance can be accessed locally without explicitly creating credentials
      - image: localstack/localstack:0.12.2 # Localstack to emulate AWS DynamoDB and S3 services
        environment:
        - EDGE_PORT=8000
        - SERVICES=s3,dynamodb
        - DEFAULT_REGION=us-east-1
        - DEBUG=1
      - image: circleci/redis:6.2-alpine # Redis service container
      - image: circleci/mongo:4.4.1 # MongoDB service container

  # Used to run container builds
  build-executor:
    parameters:
      default_resource_class:
        description: Default resource class for the executor
        type: string
        default: medium
    working_directory: ~/voiceflow
    docker:
      - image: 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-image:v4
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: << parameters.default_resource_class >>

  # Used to run node-intensive tests and builds
  node-executor:
    parameters:
      default_resource_class:
        description: Default resource class for the executor
        type: string
        default: medium+
    working_directory: ~/voiceflow
    docker:
      - image: 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-node-image:v2
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    environment:
      NODE_OPTIONS: --max-old-space-size=4096
    resource_class: << parameters.default_resource_class >>

  default-executor: # used to run the release
    parameters:
      default_resource_class:
        description: Default resource class for the executor
        type: string
        default: medium
    docker:
      - image: 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-node-image:v2
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: << parameters.default_resource_class >>

  # for go executions
  go-executor:
    resource_class: medium+
    docker:
      - image: cimg/go:1.17-node

#------------------------------------------------------------------ORBS---------------------------------------------------------------

orbs:
  slack: circleci/slack@4.2.1
  gh: circleci/github-cli@1.0


#-------------------------------------------------------------------------------------------------------------------------------------

#-------------------------------------------------------------HELM COMMANDS----------------------------------------------------------

commands:
  helm-add-repos:
    description: Add voiceflow Helm repos
    steps:
      - run:
          name: Add voiceflow Helm repos
          command: |
            helm repo add voiceflow-charts-s3 s3://voiceflow-charts 
            helm repo add voiceflow-charts-s3-private s3://voiceflow-charts-private
            helm repo add voiceflow-charts-s3-beta s3://voiceflow-charts-beta
            helm repo update

  helm-package-publish-charts:
    description: Package and publish helm charts
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
    steps:
      - run:
          name: Package and publish charts
          working_directory: << parameters.working_directory >>
          command: |
            for file in */ ; do 
              if [[ -d "$file" && -f "$file/$file/Chart.yaml" ]]; then
                echo "packaging $file";
                cd $file;
                helm dep update $file;
                helm package $file;
                pattern="*.tgz";
                chart=( $pattern );
                channel=$(cat $file/Chart.yaml | yq -r '.annotations."release-channel"')
                echo "publishing in $channel channel";
                if [[ $channel == "private" ]]; then
                  helm s3 push --force ${chart[0]} voiceflow-charts-s3-private;
                fi
                if [[ $channel == "public" ]]; then
                  helm s3 push --force ${chart[0]} voiceflow-charts-s3;
                fi
                if [[ $channel == "beta" ]]; then
                  helm s3 push --force ${chart[0]} voiceflow-charts-s3-beta;
                fi
                cd ..;
              fi; 
            done


#-------------------------------------------------------------AWS COMMANDS----------------------------------------------------------
  stop_ec2_instance:
    parameters:
      instance_id:
        description: Id of the EC2 instance
        type: string
      execute_when:
        description: When execute this command
        type: string
        default: on_success
    steps:
      - run: 
          name: Stop EC2 instance
          no_output_timeout: 30m
          when: << parameters.execute_when >>
          command: |
            EC2_INSTANCE_ID=<< parameters.instance_id >>

            aws ec2 stop-instances --instance-ids $EC2_INSTANCE_ID

  start_ec2_instance:
    parameters:
      instance_id:
        description: Id of the EC2 instance
        type: string
      execute_when:
        description: When execute this command
        type: string
        default: on_success
    steps:
      - run: 
          name: Start EC2 instance
          no_output_timeout: 30m
          when: << parameters.execute_when >>
          command: |
            EC2_INSTANCE_ID=<< parameters.instance_id >>

            aws ec2 start-instances --instance-ids $EC2_INSTANCE_ID

            aws ec2 wait instance-status-ok --instance-ids $EC2_INSTANCE_ID

  add_ip_to_security_group:
    parameters:
      sg_id:
        description: Id of the security group
        type: string
      execute_when:
        description: When execute this command
        type: string
        default: on_success
    steps:
      - run: 
          name: Add IP to Security Group
          when: << parameters.execute_when >>
          command: |
            # 1- Get the public IP of the current CircleCI runner
            PUBLIC_IP=$(curl ipinfo.io/ip)

            # 2- Get SG ID
            SG_ID=<< parameters.sg_id >>

            # 3- Add an ingress rule to the security group
            aws ec2 authorize-security-group-ingress --group-id $SG_ID \
              --protocol tcp --port 22 --cidr $PUBLIC_IP/24

  remove_ip_to_security_group:
    parameters:
      sg_id:
        description: Id of the security group
        type: string
      execute_when:
        description: When execute this command
        type: string
        default: on_success
    steps:
      - run: 
          name: Remove IP from Security Group
          when: << parameters.execute_when >>
          command: |
            # 1- Get the public IP of the current CircleCI runner
            PUBLIC_IP=$(curl ipinfo.io/ip)

            # 2- Get SG ID
            SG_ID=<< parameters.sg_id >>

            aws ec2 revoke-security-group-ingress --group-id $SG_ID \
              --protocol tcp --port 22 --cidr $PUBLIC_IP/24

#-------------------------------------------------------------UTILS COMMANDS----------------------------------------------------------

  check_commit_message:
    parameters:
      commit_message:
        description: Commit message to check
        type: string
    steps:
      - run:
          name: Check commit message
          command: |
            CHECK_COMMIT_MESSAGE=<< parameters.commit_message >>
            COMMIT_MESSAGE="$(git log --format=oneline -n 1 $CIRCLE_SHA1)"

            # If a message has been introduces, we have to check that in the commit message, if it is not included, the braches will not be synced
            # this is for the use case of the bugfix mechanism
            if [[ $COMMIT_MESSAGE != *"$CHECK_COMMIT_MESSAGE"* ]]; then
              circleci-agent step halt 
            fi

  set_yarn_bash_default_shell:
    steps:
      - run:
          name: Set Bash as a default shell for yarn commands
          command: yarn config set script-shell /bin/bash


  setup_pg:
    steps:
      - run:
          name: Install psql for seeding db
          command: |
            sudo apt update
            sudo apt install -y postgresql-client
      - run:
          name: Wait for Postgres & Dynamo Docker Images
          command: dockerize -wait tcp://localhost:5432 -timeout 1m

  setup_dynamodb:
    steps:
      - run:
          name: AWS Config
          command: ./scripts/mock_aws_credentials.sh
      - run:
          name: Wait for Dynamo Docker Image
          command: dockerize -wait tcp://localhost:8000 -timeout 1m

  setup_mongodb:
    steps:
      - run:
          name: Wait for MongoDB Docker Image
          command: dockerize -wait tcp://localhost:27017 -timeout 1m

  clone_s3_assets:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Clone S3 assets
      from:
        description: S3 URL
        type: string
      to:
        description: Path to clone S3 assets
        type: string
    steps:
      - run:
          name: << parameters.step_name >>
          command: |
            aws s3 sync << parameters.from >> << parameters.to >>

  copy_s3_asset:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Copy S3 asset
      from:
        description: S3 URL
        type: string
      to:
        description: Path to copy S3 asset
        type: string
    steps:
      - run:
          name: << parameters.step_name >>
          command: |
            aws s3 cp << parameters.from >> << parameters.to >>

  set_etc_hosts_e2e:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Set etc hosts
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
    steps:
      - run:
          name: << parameters.step_name >>
          background: << parameters.run_in_background >>
          command: |
            # Modify the hosts of the executor
            set +e
            # with sudo - machine executor
            echo '127.0.0.1 creator-app.test.e2e postgres.test.e2e redis.test.e2e localstack.test.e2e mongodb.test.e2e server-data-api.test.e2e creator-api.test.e2e luis-authoring-service.test.e2e integrations.test.e2e custom-api.test.e2e canvas-export.test.e2e alexa-runtime.test.e2e alexa-service.test.e2e general-runtime.test.e2e general-service.test.e2e google-runtime.test.e2e google-service.test.e2e realtime.test.e2e ingest.test.e2e event-ingestion-service.test.e2e' | sudo tee -a /etc/hosts > /dev/null
            # without sudo - docker executor
            echo '127.0.0.1 creator-app.test.e2e postgres.test.e2e redis.test.e2e localstack.test.e2e mongodb.test.e2e server-data-api.test.e2e creator-api.test.e2e luis-authoring-service.test.e2e integrations.test.e2e custom-api.test.e2e canvas-export.test.e2e alexa-runtime.test.e2e alexa-service.test.e2e general-runtime.test.e2e general-service.test.e2e google-runtime.test.e2e google-service.test.e2e realtime.test.e2e ingest.test.e2e event-ingestion-service.test.e2e' | tee -a /etc/hosts > /dev/null
            set -e

  clone_repo:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      github_commit:
        description: git commit hash for the repo provided
        type: env_var_name
        default: DEFAULT_COMMIT
      github_repo_name:
        description: github repo name
        type: string
      path_to_clone:
        description: Path to clone the github repo
        type: string
        default: './'
      step_name:
        description: Name of the step
        type: string
        default: Clone git repository
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
    steps:
      - run:
          name: << parameters.step_name >>
          background: << parameters.run_in_background >>
          command: |
            git clone https://${<< parameters.github_username >>}:${<< parameters.github_token >>}@github.com/voiceflow/<< parameters.github_repo_name >> << parameters.path_to_clone >>
            cd << parameters.path_to_clone >>
            git reset --hard ${<< parameters.github_commit >>}

  delete_branch:
    parameters:
      branch_name:
        description: Name of the branch to delete
        type: string
      step_name:
        description: Name of the step
        type: string
        default: Delete branch
      ssh_key:
        description: The SSH key with write permissions to the repository
        type: string
    steps:
      - add_ssh_keys: # To enable write access to repository for removing development environment branches
          fingerprints:
            - << parameters.ssh_key >>
      - run:
          name: << parameters.step_name >>
          command: |
            git push origin --delete << parameters.branch_name >> --no-verify # Clean up git branch


  sync_branches:
    parameters:
      checkout:
        description: Checkout code
        type: boolean
        default: false
      source_branch_name:
        description: Name of the source branch
        type: string
        default: "master"
      destination_branch_name:
        description: Name of the production branch
        type: string
        default: "production"
      step_name:
        description: Name of the step
        type: string
        default: Sync 2 branches
      ssh_key:
        description: The SSH key with write permissions to the repository
        type: string
      check_commit_message:
        description: The SSH key with write permissions to the repository
        type: string
        default: ""
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout
      - add_ssh_keys: # To enable write access to repository
          fingerprints:
            - << parameters.ssh_key >>
      - run:
          name: << parameters.step_name >>
          command: |

            SYNC=true
            CHECK_COMMIT_MESSAGE=<< parameters.check_commit_message >>
            COMMIT_MESSAGE="$(git log --format=oneline -n 1 $CIRCLE_SHA1)"

            # If a message has been introduces, we have to check that in the commit message, if it is not included, the braches will not be synced
            # this is for the use case of the bugfix mechanism
            if [[ $CHECK_COMMIT_MESSAGE != "" && $COMMIT_MESSAGE != *"$CHECK_COMMIT_MESSAGE"* ]]; then
              SYNC=false
            fi

            if [[ $SYNC == true ]]; then
              git fetch
              git checkout << parameters.destination_branch_name >>
              git rebase << parameters.source_branch_name >>
              git push origin << parameters.destination_branch_name >>
            else
              echo "Avoiding syncing branches"
              circleci-agent step halt 
            fi

  check_image_exists:
    description: Check if a Docker image exists
    parameters:
      image_repo:
        description: The container image repository
        type: string
      request_remote_docker:
        description: Add the option to request a new remote docker, set to false when you concat docker jobs
        type: boolean
        default: true
    steps:
      - when:
          condition: << parameters.request_remote_docker >>
          steps:
            - setup_remote_docker:  # Need this to run DinD
                version: 20.10.11
      - docker_login
      - run:
          name: If container with this git SHA already exists, don't build
          command: |
            IMAGE_REPO="<< parameters.image_repo >>"
            IMAGE_TAG="k8s-$CIRCLE_SHA1"
            IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
            set +e
            DOCKER_CLI_EXPERIMENTAL=enabled docker manifest inspect $IMAGE_NAME > /dev/null 2>&1
            SEARCH_IMAGE_RESULT=$?
            set -e

            # Store the result on a file in tmp folder to use in future steps
            if [[ $SEARCH_IMAGE_RESULT -eq 0 ]]; then
              echo 'export IMAGE_EXISTS="true"' > /tmp/IMAGE_STATUS  # Image exists, skip following steps
            else
              echo 'export IMAGE_EXISTS="false"' > /tmp/IMAGE_STATUS  # Image exists, skip following steps
            fi

  notify_slack:
    description: Notify build status on Slack Channel
    parameters:
      channel:
        description: The Slack Channel where we receive the notification
        type: string
      event:
        description: event when the notify is triggered
        enum:
          - fail
          - pass
          - always
        type: enum
      template:
        description: Slack Message template
        type: string
      mentions:
        description: Mention on the slack channel
        type: string
        default: ""
      branch_pattern:
        description: Branch pattern to allow the notification to be sent
        type: string
        default: ".*"
    steps:
      - when:
          condition: << parameters.mentions >>
          steps:
            - slack/notify:
                channel: << parameters.channel >>
                event: << parameters.event >>
                mentions: << parameters.mentions >>
                template: << parameters.template >>
                branch_pattern: << parameters.branch_pattern >>
      - unless:
          condition: << parameters.mentions >>
          steps:
            - slack/notify:
                channel: << parameters.channel >>
                event: << parameters.event >>
                template: << parameters.template >>
                branch_pattern: << parameters.branch_pattern >>

  run_command_with_retry:
    description: Run command with retry
    parameters:
      step_name:
        description: Name of the Step
        type: string
        default: "Executing Command with retry policy"
      working_directory:
        description: Directory to work on
        type: string
        default: "./"
      background:
        description: Run it in background
        type: boolean
        default: false
      command:
        description: Command to run
        type: string
      retry-count:
        description: Number of retries
        type: integer
        default: 3
      sleep:
        description: Wait duration until next retry
        type: integer
        default: 5
    steps:
      - run:
          name: << parameters.step_name >>
          working_directory: << parameters.working_directory >>
          background: << parameters.background >>
          command: |
            retry() {
              MAX_RETRY=<< parameters.retry-count >>
              error=""
              n=0
              until [ $n -ge $MAX_RETRY ]; do
                set +e
                eval "$@"
                set -e
                if [ $? -eq 0 ]; then
                  break
                fi
                  
                n=$[$n+1]
                sleep << parameters.sleep >>
              done
              if [ $n -ge $MAX_RETRY ]; then
                echo "failed: ${@}" >&2
                exit 1
              fi
            }
            retry << parameters.command >>

  setup_local_registry:
    description: Setup a local NPM registry
    parameters:
      verdaccio_config:
        description: location of verdaccio configuration file
        type: string
    steps:
      - run:
          name: Setup local proxy registry
          background: true
          command: |
            docker create -v /verdaccio/conf --name verdaccio-conf alpine:3.4 /bin/true
            docker cp << parameters.verdaccio_config >> verdaccio-conf:/verdaccio/conf

            docker run -it --name verdaccio --network host -e NPM_TOKEN=${NPM_TOKEN} --volumes-from verdaccio-conf verdaccio/verdaccio:5
      - run_command_with_retry:
          step_name: Download Docker image
          command: docker pull 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-node-build-image:v1
   
  monorepo_publish_to_local_registry:
    description: Publish all packages in monorepo to a local NPM registry
    parameters:
      working_directory:
        description: root directory of the monorepo
        type: string
        default: ./
    steps:
      - run:
          name: Publish pre-release versions to local proxy registry
          working_directory: << parameters.working_directory >>
          command: |
            docker run -d --name prepublish --network host -v /src 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-node-build-image:v1 tail -f /dev/null
            docker cp ./ prepublish:/src
            docker exec prepublish git config --global user.email "serviceaccount@voiceflow.com"
            docker exec prepublish git config --global user.name "Voiceflow"
            docker exec prepublish npx wait-on http://localhost:4873/-/ping

            docker exec -w /src prepublish npx lerna@4.0.0 publish prerelease \
              --registry=http://localhost:4873 \
              --force-publish \
              --amend \
              --exact \
              --no-verify-access \
              --no-commit-hooks \
              --yes
            docker cp prepublish:/src/. ./

#-------------------------------------------------------------TRACK COMMANDS----------------------------------------------------------

  check_track_exists:
    description: Check if a track  exists
    parameters:
      component:
        description: The container image repository
        type: string
      bucket:
        description: The container image repository
        type: string
        default: "com.voiceflow.ci.assets"
      stop_if_not_exists:
        description: Stop if the bucket does not exists
        type: boolean
        default: false
    steps:
      - run:
          name: If track does not exists, don't build
          command: |

            STOP=<< parameters.stop_if_not_exists >>

            BRANCH_NAME=$CIRCLE_BRANCH
            if [[ -z "$CIRCLE_BRANCH" && ! -z "$CIRCLE_TAG" ]]; then
              BRANCH_NAME="master"
            fi

            TRACK="tracks/<< parameters.component >>/$BRANCH_NAME"
            echo $TRACK
            set +e
            aws s3 cp s3://<< parameters.bucket >>/$TRACK /tmp/$TRACK
            SEARCH_TRACK_RESULT=$?
            set -e

            # Store the result on a file in tmp folder to use in future steps
            if [[ $SEARCH_TRACK_RESULT -eq 0 ]]; then
              echo 'export TRACK_EXISTS="true"' > /tmp/TRACK_STATUS  # Track exists, skip following steps
            else
              echo 'export TRACK_EXISTS="false"' > /tmp/TRACK_STATUS  # Track exists, skip following steps
              if [[ $STOP == true ]]; then
                curl --request POST \
                  --url https://circleci.com/api/v2/workflow/$CIRCLE_WORKFLOW_ID/cancel \
                  --header "Circle-Token: ${CIRCLECI_API_TOKEN}"
              fi
            fi

  update_database_track:
    description: Update Database Track
    parameters:
      component:
        description: The component type for development environment deployment
        type: string
      checkout:
        description: Determines if a checkout will be executed or not
        type: boolean
        default: true
      bucket:
        description: The container image repository
        type: string
        default: "com.voiceflow.ci.assets"
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout # special step to check out source code to working directory
      - check_track_exists:
          component: << parameters.component >>
      - attach_workspace:
          at: ~/voiceflow
      - run:
          name: Update Track
          command: |
            # Load TRACK_EXISTS variable from file previously stored in the tmp folder
            source "/tmp/TRACK_STATUS"

            set +e  # Don't exit on the any error (for semantic-release)
            npx semantic-release@17 --prepare --dry-run | tee sem_release.output  # print semver to screen and force return 0
            SEM_VER=$(cat sem_release.output | grep 'The next release version is' | awk '{print $NF}')  # Get release semver
            set -e  # Don't exit on the any error (for semantic-release)

            if [[ $TRACK_EXISTS == "true"  && ! -z "$SEM_VER" ]]; then
              # update the track
              TRACK="tracks/<< parameters.component >>/$CIRCLE_BRANCH"
              echo $TRACK
              echo $SEM_VER > /tmp/$TRACK
              aws s3 cp /tmp/$TRACK s3://<< parameters.bucket >>/$TRACK
            else
              echo "Track does not exist! avoiding update!"
            fi

  update_track:
    description: Update Component Track
    parameters:
      image_repo:
        description: The container image repository
        type: string
      component:
        description: The component type for development environment deployment
        type: string
      dockerfile:
        description: Name of the Dockerfile to build
        type: string
        default: Dockerfile
      build_args:
        description: Arguments to pass while building the docker image
        type: string
        default: ''
      build_context:
        description: Path to the context for the docker build
        type: string
        default: '.'
      checkout:
        description: Determines if a checkout will be executed or not
        type: boolean
        default: true
      request_remote_docker:
        description: Add the option to request a new remote docker, set to false when you concat docker jobs
        type: boolean
        default: true
      bucket:
        description: The container image repository
        type: string
        default: "com.voiceflow.ci.assets"
      check_track_exists:
        description: checks if the track exists
        type: boolean
        default: true
      local_registry:
        description: Use a local proxy registry to publish alpha version of all libraries in monorepo (must have a /config/verdaccio/config.yaml file)
        type: boolean
        default: false
      force_execute:
        description: force to update the build, if there is a change or not.
        type: boolean
        default: false
      package:
        description: Monorepo package.
        type: string
        default: ""
      image_tag:
        description: The container image tag
        type: string
        default: ""
      kms_key:
        description: KMS Key to sign the containers
        type: string
        default: "awskms:///2e64fa98-d1b0-491a-acf6-1f5fc6f94ecf"
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout # special step to check out source code to working directory
      - when:
          condition:
            and:
              - equal: [false, << parameters.force_execute >>]
              - not:
                  equal: ["", << parameters.package >>]
          steps:
            - stop_if_no_changes:
                package: << parameters.package >>
      - when:
          condition: << parameters.request_remote_docker >>
          steps:
            - setup_remote_docker: # Need this to run DinD
                version: 20.10.11
      - docker_login
      - attach_workspace:
          at: ~/voiceflow
      - check_image_exists:
          image_repo: << parameters.image_repo >>
          request_remote_docker: false
      - when:
          condition: << parameters.check_track_exists >>
          steps:
            - check_track_exists:
                component: << parameters.component >>
                bucket: << parameters.bucket >>
      - when:
          condition: << parameters.local_registry >>
          steps:
            - setup_local_registry:
                verdaccio_config: config/verdaccio/config.yaml
            - monorepo_publish_to_local_registry
      - run:
          name: "Building image and uploading track"
          command: |
            # Load IMAGE_EXISTS variable from file previously stored in the tmp folder
            source "/tmp/IMAGE_STATUS"
            # Load TRACK_EXISTS variable from file previously stored in the tmp folder
            source "/tmp/TRACK_STATUS"

            BRANCH_NAME=$CIRCLE_BRANCH
            if [[ -z "$CIRCLE_BRANCH" && ! -z "$CIRCLE_TAG" ]]; then
              BRANCH_NAME="master"
            fi

            if [[ $TRACK_EXISTS == "true" ]]; then
              IMAGE_REPO="<< parameters.image_repo >>"
              IMAGE_TAG_OVERRIDE="<< parameters.image_tag >>"
              KMS_KEY="<< parameters.kms_key >>"
              if [[ "$IMAGE_TAG_OVERRIDE" == "" ]]; then
                IMAGE_TAG="k8s-$CIRCLE_SHA1"
              else
                IMAGE_TAG="$IMAGE_TAG_OVERRIDE"
              fi

              IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
              PACKAGE="<< parameters.package >>"
              # Get the tag that is running right now
              if [[ "$CIRCLE_BRANCH" == "master" || "$CIRCLE_BRANCH" == "production" ]]; then
                  # Update the tags
                  git fetch --tags
                  SEM_VER=$(git describe --abbrev=0 --tags)
                if [[ ! -z "$PACKAGE" ]]; then
                  SEM_VER=$(git describe --abbrev=0 --tags --match "@voiceflow/$PACKAGE@*" $CIRCLE_SHA1)
                  SEM_VER=$(echo ${SEM_VER##*@})
                fi
              else
                SEM_VER=$CIRCLE_BRANCH-$CIRCLE_SHA1
              fi
              echo -e "Building with SEM_VER=$SEM_VER"

              if [[ $IMAGE_EXISTS == "false" || "$CIRCLE_BRANCH" == "master" || "$CIRCLE_BRANCH" == "production" ]]; then
                # Build Docker Image
                echo "Image not found, building..."
                docker build \
                  --build-arg build_BUILD_NUM=${CIRCLE_BUILD_NUM} \
                  --build-arg build_GITHUB_TOKEN=${GITHUB_TOKEN} \
                  --build-arg build_BUILD_URL=${CIRCLE_BUILD_URL}	\
                  --build-arg build_GIT_SHA=${CIRCLE_SHA1} \
                  --build-arg build_SEM_VER=${SEM_VER} \
                  <<# parameters.local_registry >> \
                    --network host \
                    --build-arg build_REGISTRY_URL=http://localhost:4873 \
                  <</ parameters.local_registry >> \
                  <<^ parameters.local_registry >> \
                    --build-arg NPM_TOKEN=//registry.npmjs.org/:_authToken=${NPM_TOKEN} \
                  <</ parameters.local_registry >> \
                  << parameters.build_args >> \
                  -f << parameters.build_context >>/<< parameters.dockerfile >> \
                  -t $IMAGE_NAME << parameters.build_context >>
                docker push $IMAGE_NAME

                # Signing Docker Image
                cosign sign --key $KMS_KEY $IMAGE_NAME

                # if a tag is set, do not push to latest-$BRANCH_NAME
                if [[ "$IMAGE_TAG_OVERRIDE" == "" ]]; then
                  # Change all non alphanumeric characters to -
                  BRANCH_NAME=$(echo $CIRCLE_BRANCH | sed 's/[^a-zA-Z0-9]/-/g')
                  if [[ -z "$CIRCLE_BRANCH" && ! -z "$CIRCLE_TAG" ]]; then
                    BRANCH_NAME="master"
                  fi
                  
                  docker tag $IMAGE_NAME $IMAGE_REPO:latest-$BRANCH_NAME
                  docker push $IMAGE_REPO:latest-$BRANCH_NAME

                  # Signing Docker Image
                  cosign sign --key $KMS_KEY $IMAGE_REPO:latest-$BRANCH_NAME
                fi
              fi

              # Pull the image to get the sha is needed. 
              # If the image has been built, the following command will not pull the image because it exists locally
              TMPFILE=$(mktemp)
              docker pull $IMAGE_NAME | tee -a "$TMPFILE"
              # Get image SHA
              IMAGE_SHA=$(awk '/Digest: / {print $2}' "$TMPFILE")
              # Remove the sha256: string
              IMAGE_SHA=$(echo $IMAGE_SHA | sed 's/sha256://')
              rm "$TMPFILE"

              # update the track
              TRACK="tracks/<< parameters.component >>/$CIRCLE_BRANCH"
              echo $TRACK
              pip3 install yq
              # the file /tmp/$TRACK is downloaded in the check_track_exists step
              yq -y -i --arg tag "${IMAGE_TAG}" '."<< parameters.component >>".image.tag=$tag' /tmp/$TRACK
              yq -y -i --arg sha "${IMAGE_SHA}" '."<< parameters.component >>".image.sha=$sha' /tmp/$TRACK
              aws s3 cp /tmp/$TRACK s3://<< parameters.bucket >>/$TRACK

            else
              echo "Track does not exist! avoiding update!"
            fi

  skip_while_draft:
    steps:
        - gh/setup
        - run:
            name: Skip current job if pull request is draft
            command: |
              REPO=$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME
              PR_NUMBER=${CIRCLE_PULL_REQUEST##*/}

              if [ -z "$PR_NUMBER" ]; then
                if [[ "$CIRCLE_BRANCH" == "master" || $CIRCLE_BRANCH == "production" ]]; then
                  echo "Always run e2e tests on changes to master"
                else
                  echo "No PR associated with branch; skipping rest of job"
                  circleci-agent step halt
                fi
              else
                echo "Checking whether PR $PR_NUMBER is draft"
                IS_DRAFT=$(gh pr view $PR_NUMBER --repo $REPO --json isDraft --jq '.isDraft')
                if $IS_DRAFT; then
                  echo "PR $PR_NUMBER is a draft; skipping rest of job"
                  circleci-agent step halt
                else
                  echo "PR $PR_NUMBER is not a draft; continuing job"
                fi
              fi

  trigger_tags_pipelines:
    description: Triggers the CircleCI pipeline for every tag in the provided list
    parameters:
      published_tags:
        description: Environment variable in which to store the list of tags to trigger
        type: env_var_name
    steps:
      - run:
          name: Trigger Pipelines for each updated tag
          command: |
             for TAG in ${<< parameters.published_tags >>}
             do
               curl -u ${CIRCLECI_API_TOKEN}: -X POST --header 'Content-Type: application/json'  -d "{\"tag\":\"$TAG\", \"parameters\": {}}"  https://circleci.com/api/v2/project/github/$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME/pipeline
             done

#-------------------------------------------------------------YARN COMMANDS----------------------------------------------------------


  yarn_command:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Deploy application
      yarn_command:
        description: Yarn command to execute
        type: string
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_image:
        description: Container image to run the yarn command
        type: string
        default: "168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-node-build-image:v1"
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
      monorepo_package:
        description: Monorepo Package Name
        type: string
        default: ""
    steps:
      - when:
          condition: << parameters.wait >>
          steps:
            - run:
                name: Waiting util other processes are finished
                command: |

                  while [ "$(ls -A /tmp/lock)" != "" ]
                  do
                    if [ -f "/tmp/failure" ]; then
                      echo "A failure was detected in previous steps."
                      exit 1
                    fi

                    echo "Process not finished. Waiting..."
                    sleep 5
                  done

                  echo "Process finished"
      - when:
          condition: << parameters.run_in_background >>
          steps:
            - run:
                name: Create lock for << parameters.step_name >>
                command: |
                  # Create the folder if not exists
                  [ ! -d /tmp/lock ] && mkdir -p /tmp/lock

                  LOCK_FILE="/tmp/lock/$(uuidgen)"

                  touch $LOCK_FILE
                  echo "Lock created at $LOCK_FILE"
                  echo "export LOCK_FILE=$LOCK_FILE" >> $BASH_ENV
      - when:
          condition: << parameters.request_remote_docker >>
          steps:
            - setup_remote_docker:  # Need this to run DinD
                version: 20.10.11
      - when:
          condition: << parameters.run_in_container >>
          steps:
            - docker_login
            - run_command_with_retry:
                step_name: Download Docker image
                command: docker pull << parameters.container_image >>
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_background >>
          name: << parameters.step_name >>
          command: |
            RUN_IN_CONTAINER=<< parameters.run_in_container >>
            RUN_IN_BACKGROUND=<< parameters.run_in_background >>
            FOLDER_TO_COPY="<< parameters.container_folder_to_copy >>"
            MONOREPO_PACKAGE="<< parameters.monorepo_package >>"

            trap 'echo "fail detected"; touch /tmp/failure' ERR

            if [[ $RUN_IN_CONTAINER == true ]]; then
              echo "Running in a container"
              docker create -v /code --name code << parameters.container_image >> /bin/true
              docker cp $PWD/. code:/code

              # Executes Yarn command in container
              docker run --name runner -it --volumes-from code -w /code << parameters.container_image >> /bin/bash -c "<< parameters.yarn_command >>"
              # If a folder is specified we copy that one on the host
              if [[ $FOLDER_TO_COPY != "" ]]; then
                DESTINATION_FOLDER=$PWD
                if [[ $MONOREPO_PACKAGE != "" ]]; then
                  DESTINATION_FOLDER="$PWD/packages/$MONOREPO_PACKAGE"
                fi
              
                docker cp runner:/code/<< parameters.container_folder_to_copy >> $DESTINATION_FOLDER

                echo "Copying into $DESTINATION_FOLDER"
              else
                #Copy all
                echo "Copying all"
                docker cp runner:/code/. ./
              fi
            else
              # Executes Yarn command outside container
              echo "Running without a container"
              << parameters.yarn_command >>
            fi

            # Remove lock file when it is running in background/parallel
            if [[ $RUN_IN_BACKGROUND == true ]]; then
              echo "Removing Lock $LOCK_FILE"
              rm -rf $LOCK_FILE
            fi

  serverless_deploy:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      environment:
        description: environment where to deploy the serverless application
        type: string
        default: dev
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Deploy application
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          run_in_container: << parameters.run_in_container >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn serverless:deploy-<< parameters.environment >> << parameters.extra_args >>

  build:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Build
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
      container_image_to_build:
        description: Container image to run the build
        type: string
        default: "168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-node-build-image:v1"
      package:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          run_in_container: << parameters.run_in_container >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          container_image: << parameters.container_image_to_build >>
          monorepo_package: << parameters.package >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn build<<# parameters.package >>:<</ parameters.package >><< parameters.package >> << parameters.extra_args >>

  lint_report:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Generate Lint report
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn lint:report << parameters.extra_args >>

  lint_source:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Lint source
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn lint:quiet << parameters.extra_args >>

  lint_dockerfile:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Lint dockerfiles
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn lint:dockerfiles << parameters.extra_args >>

  analyze_dependencies:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_backgorund:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Analyze dependencies
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_backgorund >>
          name: << parameters.step_name >>
          command: |
            yarn analyze:dependencies << parameters.extra_args >>

  stress_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Stress Tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn test:stress << parameters.extra_args >>

  unit_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Unit Tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn test:unit << parameters.extra_args >>

  integration_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Integration Tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - set_etc_hosts_e2e
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn test:integration << parameters.extra_args >>

  smoke_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Smoke tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn test:smoke << parameters.extra_args >>

  dependency_tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Dependency tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn test:dependencies << parameters.extra_args >>


  tests:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Run all tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn test << parameters.extra_args >>

  start_e2e:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Start in e2e mode
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn e2e

  gen_certs:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      step_name:
        description: Name of the step
        type: string
        default: Generate certificates
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn gen-certs

  gen_certs_e2e:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      step_name:
        description: Name of the step
        type: string
        default: Generate certificates for e2e tests
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - yarn_command:
          working_directory: << parameters.working_directory >>
          run_in_background: << parameters.run_in_background >>
          request_remote_docker: << parameters.request_remote_docker >>
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          run_in_container: << parameters.run_in_container >>
          step_name: << parameters.step_name >>
          wait: << parameters.wait >>
          yarn_command: yarn gen-certs:e2e

  authenticate_npm:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_background >>
          name: authenticate npm
          command: echo "//registry.npmjs.org/:_authToken=$NPM_TOKEN" >> ~/.npmrc

  vf_restore_cache:
    parameters:
      yarn_lock_restore_cache_directory:
        description: Cache directory for yarn.lock file
        type: string
        default: './'
      cache_prefix:
        description: Cache prefix
        type: string
        default: ''
    steps:
      - restore_cache:
          keys:
            - node-module-cache-<< parameters.cache_prefix >>-{{ .Environment.CACHE_VERSION }}-{{ checksum "<< parameters.yarn_lock_restore_cache_directory >>/yarn.lock" }}

  vf_save_cache:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      cache_prefix:
        description: Cache prefix
        type: string
        default: ''
    steps:
      - save_cache: # special step to save the dependency cache
          key: node-module-cache-<< parameters.cache_prefix >>-{{ .Environment.CACHE_VERSION }}-{{ checksum "<< parameters.working_directory >>/yarn.lock" }}
          paths:
            - << parameters.working_directory >>/node_modules

  install_node_modules:
    parameters:
      install_args:
        description: Additional yarn install command options
        type: string
        default: ""
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      step_name:
        description: Name of the step
        type: string
        default: Install node modules
      yarn_lock_restore_cache_directory:
        description: Cache directory for yarn.lock file
        type: string
        default: './'
      cache_prefix:
        description: Cache prefix
        type: string
        default: ''
      avoid_post_install_scripts:
        description: Skip running post install scripts
        type: boolean
        default: true
      run_in_background:
        description: Run yarn install in background mode
        type: boolean
        default: false
      wait:
        description: wait until all the commands are finished
        type: boolean
        default: false
      run_in_container:
        description: Run build in a container
        type: boolean
        default: false
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: false
      container_folder_to_copy:
        description: Container folder to copy after the execution
        type: string
        default: ""
    steps:
      - authenticate_npm
      - vf_restore_cache:
          yarn_lock_restore_cache_directory: << parameters.yarn_lock_restore_cache_directory >>
          cache_prefix: << parameters.cache_prefix >>
      - when:
          condition: << parameters.avoid_post_install_scripts >>
          steps:
            - yarn_command:
                working_directory: << parameters.working_directory >>
                run_in_background: << parameters.run_in_background >>
                request_remote_docker: << parameters.request_remote_docker >>
                container_folder_to_copy: << parameters.container_folder_to_copy >>
                run_in_container: << parameters.run_in_container >>
                step_name: << parameters.step_name >>
                wait: << parameters.wait >>
                yarn_command: yarn install --frozen-lockfile --ignore-scripts << parameters.install_args >> 2>&1 | tee output.file
      - unless:
          condition: << parameters.avoid_post_install_scripts >>
          steps:
            - yarn_command:
                working_directory: << parameters.working_directory >>
                run_in_background: << parameters.run_in_background >>
                request_remote_docker: << parameters.request_remote_docker >>
                container_folder_to_copy: << parameters.container_folder_to_copy >>
                run_in_container: << parameters.run_in_container >>
                step_name: << parameters.step_name >>
                wait: << parameters.wait >>
                yarn_command: yarn install --frozen-lockfile  << parameters.install_args >>
      - run:
          working_directory: << parameters.working_directory >>
          name: Check yarn lock integrity
          command: |
            diff=$(git diff --stat)
            clean=$(echo $diff | { grep "yarn.lock" || true; })
            if [[ -z "$clean" ]]; then
              echo "Lockfile ok."
              exit 0
            else
              echo "The lockfile is wrong. Need changes."
              exit 1
            fi

      - vf_save_cache: # special step to save the dependency cache
          working_directory: << parameters.working_directory >>
          cache_prefix: << parameters.cache_prefix >>

#-------------------------------------------------------------DOCKER COMMANDS----------------------------------------------------------
  docker_login:
    steps:
      - run:
          name: "Docker login"
          command: |
            $(aws ecr get-login --no-include-email --region us-east-1)

  build_push_image:
    parameters:
      image_repo:
        description: The container image repository
        type: string
      image_tag:
        description: The container image tag
        type: string
        default: ""
      dockerfile:
        description: Name of the Dockerfile to build
        type: string
        default: Dockerfile
      build_context:
        description: Path to the context for the docker build
        type: string
        default: '.'
      checkout:
        description: Determines if a checkout will be executed or not
        type: boolean
        default: true
      request_remote_docker:
        description: Add the option to request a new remote docker, set to false when you concat docker jobs
        type: boolean
        default: true
      monorepo_directory:
        description: the root directory of monorepo, uses a local registry to pre-release package versions
        type: string
        default: ""
      package:
        description: The monorepo package that has been changed
        type: string
        default: ""
      force_execute:
        description: force to notify, if there is a change or not.
        type: boolean
        default: false
      kms_key:
        description: KMS Key to sign the containers
        type: string
        default: "awskms:///2e64fa98-d1b0-491a-acf6-1f5fc6f94ecf"
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout # special step to check out source code to working directory
      - when:
          condition:
            and:
              - equal: [false, << parameters.force_execute >>]
              - not:
                  equal: ["", << parameters.package >>]
          steps:
            - stop_if_no_changes:
                package: << parameters.package >>
      - when:
          condition: << parameters.request_remote_docker >>
          steps:
            - setup_remote_docker:  # Need this to run DinD
                version: 20.10.11
      - attach_workspace:
          at: ~/voiceflow
      - docker_login
      - when:
          condition: << parameters.monorepo_directory >>
          steps:
            - setup_local_registry:
                verdaccio_config: << parameters.monorepo_directory >>/config/verdaccio/config.yaml
            - monorepo_publish_to_local_registry:
                working_directory: << parameters.monorepo_directory >>
      - run:
          name: "Build docker image"
          command: |
            IMAGE_TAG_OVERRIDE="<< parameters.image_tag >>"
            if [[ "$IMAGE_TAG_OVERRIDE" == "" ]]; then
              IMAGE_TAG="k8s-$CIRCLE_SHA1"
            else
              IMAGE_TAG="$IMAGE_TAG_OVERRIDE"
            fi
            IMAGE_REPO="<< parameters.image_repo >>"
            IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
            PACKAGE="<< parameters.package >>"
            # Semantic release from the current tags
            if [[ "$CIRCLE_BRANCH" == "master" || "$CIRCLE_BRANCH" == "production" ]]; then
                # Update the new tags
                git fetch --tags
                SEM_VER=$(git describe --abbrev=0 --tags)
              if [[ ! -z "$PACKAGE" ]]; then
                SEM_VER=$(git describe --abbrev=0 --tags --match "@voiceflow/$PACKAGE@*" $CIRCLE_SHA1)
                SEM_VER=$(echo ${SEM_VER##*@})
              fi
            else
              SEM_VER=$CIRCLE_BRANCH-$CIRCLE_SHA1
            fi
            echo -e "Building with SEM_VER=$SEM_VER"

            docker build \
              <<# parameters.monorepo_directory >> \
                --network host \
                --build-arg build_REGISTRY_URL=http://localhost:4873 \
              <</ parameters.monorepo_directory >> \
              <<^ parameters.monorepo_directory >> \
                --build-arg NPM_TOKEN=//registry.npmjs.org/:_authToken=${NPM_TOKEN} \
              <</ parameters.monorepo_directory >> \
              --build-arg build_BUILD_NUM=${CIRCLE_BUILD_NUM} \
              --build-arg build_BUILD_URL=${CIRCLE_BUILD_URL}	\
              --build-arg build_GITHUB_TOKEN=${GITHUB_TOKEN} \
              --build-arg build_GIT_SHA=${CIRCLE_SHA1} \
              --build-arg build_SEM_VER=${SEM_VER} \
              -f << parameters.build_context >>/<< parameters.dockerfile >> \
              -t $IMAGE_NAME << parameters.build_context >>
      - run:
          name: "Push docker images"
          command: |
            IMAGE_TAG_OVERRIDE="<< parameters.image_tag >>"
            KMS_KEY="<< parameters.kms_key >>"
            if [[ "$IMAGE_TAG_OVERRIDE" == "" ]]; then
              IMAGE_TAG="k8s-$CIRCLE_SHA1"
            else
              IMAGE_TAG="$IMAGE_TAG_OVERRIDE"
            fi
            IMAGE_REPO="<< parameters.image_repo >>"
            IMAGE_NAME="$IMAGE_REPO:$IMAGE_TAG"
            docker push $IMAGE_NAME

            # Signing Docker Image
            cosign sign --key $KMS_KEY $IMAGE_NAME

            # if a tag is set, do not push to latest-$BRANCH_NAME
            if [[ "$IMAGE_TAG_OVERRIDE" == "" ]]; then
              BRANCH_NAME=$(echo $CIRCLE_BRANCH | sed 's/[^a-zA-Z0-9]/-/g')
              if [[ -z "$CIRCLE_BRANCH" && ! -z "$CIRCLE_TAG" ]]; then
                BRANCH_NAME="master"
              fi
              docker tag $IMAGE_NAME $IMAGE_REPO:latest-$BRANCH_NAME
              docker push $IMAGE_REPO:latest-$BRANCH_NAME

              # Signing Docker Image
              cosign sign --key $KMS_KEY $IMAGE_REPO:latest-$BRANCH_NAME
            fi

  post_image_push_actions:
    description: Deploy an image into a K8s cluster
    parameters:
      namespace:
        description: The namespace the target resides in
        type: string
      tagged:
        description: Running on a git tag?
        type: boolean
        default: false
      success_slack_notify:
        description: Post to Slack on successful deployment?
        type: boolean
        default: true
      sentry:
        description: Report deployment to sentry
        type: boolean
        default: false
      ssh_key:
        description: The SSH key with write permissions to the repository
        type: string
        default: "4c:f6:5f:e5:7a:e9:b4:03:91:6a:93:e5:0e:60:c2:a6"
      component:
        description: The component name that has changed
        type: string
        default: ""
      package:
        description: The monorepo package that has been changed
        type: string
        default: ""
      force_execute:
        description: force to notify, if there is a change or not.
        type: boolean
        default: false
    steps:
      - checkout
      - when:
          condition:
            and:
              - equal: [false, << parameters.force_execute >>]
              - not:
                  equal: ["", << parameters.package >>]
          steps:
            - stop_if_no_changes:
                package: << parameters.package >>
      - add_ssh_keys: # To enable write access to repository
          fingerprints:
            - << parameters.ssh_key >>
      - run:
          name: Post Image Push Actions
          command: |
            START_TIME=$(date +%s)

            if [[ "<< parameters.tagged >>" != "false" ]]; then
              sleep 60

              #Production
              aws eks --region us-east-1 update-kubeconfig --name cm4-production-0-p0

              #Cloud Snapshot
              aws s3 cp s3://com.voiceflow.ci.assets/scripts/cloud_snapshot.sh cloud_snapshot.sh
              chmod +x cloud_snapshot.sh
              ./cloud_snapshot.sh << parameters.namespace >> << parameters.component >> << parameters.package >>

              #FIXME THIS IS A WA with a problem with the Slack Orb and dynamic templates
              export DEPLOY_TEMPLATE=$(cat /tmp/voiceflow/common/deploy_app_template.json)
              export SLACK_PARAM_TEMPLATE=DEPLOY_TEMPLATE
              export SLACK_PARAM_CHANNEL="deployed_versions"
              aws s3 cp s3://com.voiceflow.ci.assets/scripts/slack_notify.sh slack_notify.sh
              chmod +x slack_notify.sh
              ./slack_notify.sh

              if [[ "<< parameters.sentry >>" != "false" ]]; then
                END_TIME=$(date +%s)
                npm config set unsafe-perm true
                npx @sentry/cli@1 releases deploys "${CIRCLE_TAG:1}" new -e public -t $((END_TIME-START_TIME))
              fi
            fi

      - when:
          condition: << parameters.tagged >>
          steps:
            - when:
                condition: <<parameters.success_slack_notify>>
                steps:
                - notify_slack:
                    channel: product_releases
                    event: pass
                    template: success_tagged_deploy_1
            - notify_slack:
                channel: product_releases
                event: fail
                mentions: "@engteam"
                template: basic_fail_1

#-------------------------------------------------------------E2E COMMANDS----------------------------------------------------------
  clone_vf_service:
    parameters:
      service_name:
        description: Name of the Voiceflow service
        type: string
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for service repo
        type: env_var_name
        default: DEFAULT_COMMIT
      yarn_install_extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - clone_repo:
          step_name: "Clone << parameters.service_name >> repository"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_repo_name: "<< parameters.service_name >>"
          github_commit: "<< parameters.commit >>"
          path_to_clone: "~/<< parameters.service_name >>"
      - install_node_modules:
          install_args: "<< parameters.yarn_install_extra_args >>"
          avoid_post_install_scripts: false
          working_directory: "~/<< parameters.service_name >>"
          yarn_lock_restore_cache_directory: "~/<< parameters.service_name >>"
      - run:
          name: Generate e2e start script
          working_directory: "~/<< parameters.service_name >>"
          command: |
            cat > ./start_e2e.sh \<< \EOF
            #! /bin/bash

            set -e

            cd ~/<< parameters.service_name >>
            yarn gen-certs:e2e
            yarn e2e

            EOF

            chmod +x ./start_e2e.sh

  setup_vf_service_docker:
    parameters:
      service_name:
        description: Name of the Voiceflow service
        type: string
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for service repo
        type: env_var_name
        default: DEFAULT_COMMIT
      yarn_install_extra_args:
        description: Additional yarn command options
        type: string
        default: ""
    steps:
      - clone_repo:
          step_name: "Clone << parameters.service_name >> repository"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_repo_name: "<< parameters.service_name >>"
          github_commit: "<< parameters.commit >>"
          path_to_clone: "~/<< parameters.service_name >>"
      - install_node_modules:
          install_args: "<< parameters.yarn_install_extra_args >>"
          avoid_post_install_scripts: false
          working_directory: "~/<< parameters.service_name >>"
          yarn_lock_restore_cache_directory: "~/<< parameters.service_name >>"
      - gen_certs_e2e:
          step_name: "Set up << parameters.service_name >>"
          working_directory: "~/<< parameters.service_name >>"
      - start_e2e:
          step_name: "Start << parameters.service_name >>"
          run_in_background: true
          working_directory: "~/<< parameters.service_name >>"
      - check_e2e_deps:
          step_name: "Start << parameters.service_name >>"
          working_directory: "~/<< parameters.service_name >>"


  setup_vf_service_machine:
    parameters:
      vf_service_name:
        description: username for cloning git repositories
        type: string
      vf_service_port:
        description: port of the service to expose
        type: string
      vf_service_install_args:
        description: Extra args while installing the service
        type: string
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      vf_service_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: CIRCLE_SHA1
      vf_service_endpoint_to_wait:
        description: Custom endpoint to wait
        type: string
        default: ""
    steps:
      - clone_repo:
          step_name: "Downloading << parameters.vf_service_name >>"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_commit: "<< parameters.vf_service_commit >>"
          github_repo_name: "<< parameters.vf_service_name >>"
          path_to_clone: "~/code/<< parameters.vf_service_name >>"
      - vf_restore_cache:
          yarn_lock_restore_cache_directory: ~/code/<< parameters.vf_service_name >>
          cache_prefix: e2e-machine
      - authenticate_npm:
          working_directory: ~/code/<< parameters.vf_service_name >>
      - run:
          name: Build << parameters.vf_service_name >>
          working_directory: ~/code/<< parameters.vf_service_name >>
          command: |
            # Set Node 16
            nvm install v16.13.0
            nvm use v16.13.0
            nvm alias default v16.13.0
            yarn install --frozen-lockfile --cache-folder=".yarn-cache" << parameters.vf_service_install_args >>
            yarn build
      - vf_save_cache:
            working_directory: ~/code/<< parameters.vf_service_name >>
            cache_prefix: e2e-machine

      - run:
          name: Removing << parameters.vf_service_name >> from Docker Stack
          working_directory: "~/code/infrastructure-e2e"
          command: |
            docker-compose -p vf -f docker-compose-vf.yaml rm -f -s << parameters.vf_service_name >>-e2e
      - run_command_with_retry:
          step_name: Download Docker image
          command: docker pull 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1
      - run:
          name: Setup << parameters.vf_service_name >>
          working_directory: ~/code
          command: |
            # copy a config file into this volume and the npm token
            docker cp << parameters.vf_service_name >> code:/code
            docker cp ~/.npmrc code:/code/<< parameters.vf_service_name >>
            # start an application container using this volume
            docker run \
              --workdir /code/<< parameters.vf_service_name >> \
              --detach \
              --expose << parameters.vf_service_port >> \
              --publish << parameters.vf_service_port >>:<< parameters.vf_service_port >> \
              --name << parameters.vf_service_name >>-e2e \
              --hostname << parameters.vf_service_name >>.test.e2e \
              --network="vf_voiceflow" \
              --volumes-from code \
              --volume vf_certs:/code/<< parameters.vf_service_name >>/certs \
              --volume vf_caroot:/usr/local/share/ca-certificates \
              168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1  \
              /bin/bash -c "update-ca-certificates && yarn install --force && yarn e2e"
      - run:
          name: Wait << parameters.vf_service_name >>
          working_directory: ~/code/<< parameters.vf_service_name >>
          command: |
            CUSTOM_ENDPOINT=<<parameters.vf_service_endpoint_to_wait >>
            if [[ $CUSTOM_ENDPOINT == "" ]]; then
              npx wait-on https://<< parameters.vf_service_name >>.test.e2e:<< parameters.vf_service_port >>/health
            else
              npx wait-on $CUSTOM_ENDPOINT
            fi


  setup_vf_dbs_machine:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
    steps:
      - clone_repo:
          step_name: "Downloading dbcli"
          github_username: "<< parameters.github_username >>"
          github_token:  "<< parameters.github_token >>"
          github_repo_name: "database-cli"
          path_to_clone: "~/code/database-cli"
          github_commit: "<< parameters.commit >>"

      - vf_restore_cache:
          yarn_lock_restore_cache_directory: ~/code/database-cli
          cache_prefix: e2e-machine
      - authenticate_npm:
          working_directory: ~/code/database-cli

      - run:
          name: Install dbcli
          working_directory: ~/code/database-cli
          background: true
          command: |  
            # Set Node 16
            nvm install v16.13.0
            nvm use v16.13.0
            nvm alias default v16.13.0
            yarn install --frozen-lockfile --cache-folder=".yarn-cache"

            touch /tmp/dbcli_finished.txt


  setup_vf_dbs_docker:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
      cache_prefix:
        description: Cache prefix
        type: string
        default: ""
      initialize_database:
        description: Run database initialization after install
        type: boolean
        default: true
      working_directory:
        description: Directory containing package.json
        type: string
        default: '~/database-cli'
    steps:
      - clone_repo:
          step_name: "Clone database-cli repository"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_repo_name: database-cli
          github_commit: "<< parameters.commit >>"
          path_to_clone: << parameters.working_directory >>
      - install_node_modules:
          working_directory: << parameters.working_directory >>
          yarn_lock_restore_cache_directory: << parameters.working_directory >>
          cache_prefix: << parameters.cache_prefix >>
      - when:
          condition: << parameters.initialize_database >>
          steps:
            - run:
                name: Setup Database
                working_directory: << parameters.working_directory >>
                command: |
                  yarn init:e2e

  setup_vf_creator_app_docker:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
    steps:
      - checkout:
          path: ~/creator-app
      - run:
          name: Setup creator-app .env.local
          working_directory: ~/creator-app/packages/creator-app
          command: |
            echo 'VF_APP_API_HOST=localhost' >> .env.local
            echo 'VF_APP_FF_DATA_REFACTOR=true' >> .env.local
      - install_node_modules:
          avoid_post_install_scripts: false
          working_directory: ~/creator-app
          yarn_lock_restore_cache_directory: ~/creator-app
      - run:
          name: Build dependencies
          command: yarn build:deps
          working_directory: ~/creator-app
      - gen_certs_e2e:
          step_name: Generate certificates creator-app
          working_directory: ~/creator-app/packages/creator-app
      - run:
          name: Setup creator-app
          working_directory: ~/creator-app/packages/creator-app
          no_output_timeout: 15m
          command: |
            yarn build:e2e
            yarn start:e2e

  setup_vf_creator_app_machine:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      creator_app_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: CIRCLE_SHA1
      build_dependencies_command:
        description: command to call when building dependencies for the monorepo
        type: string
        default: yarn build:deps
    steps:
      - clone_repo:
          step_name: "Downloading Creator App"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_commit: "<< parameters.creator_app_commit >>"
          github_repo_name: "creator-app"
          path_to_clone: "~/code/creator-app"
      - vf_restore_cache:
          yarn_lock_restore_cache_directory: ~/code/creator-app
          cache_prefix: e2e-machine
      - authenticate_npm:
          working_directory: ~/code/creator-app
      - run:
          name: Build creator app
          working_directory: ~/code/creator-app
          background: true
          command: |
            # Set Node 16
            nvm install v16.13.0
            nvm use v16.13.0
            nvm alias default v16.13.0
            yarn install --frozen-lockfile --cache-folder=".yarn-cache"

            << parameters.build_dependencies_command >>

            cd packages/creator-app
            yarn build:e2e

            touch /tmp/creator_app_finished.txt

#-------------------------------------------------------------MONOREPO COMMANDS----------------------------------------------------------

  monorepo_exec_command_when_package_changed:
    description: execute commands
    parameters:
      command:
        description: command to execute
        type: string
      extra_parameters:
        description: command to execute
        type: string
        default: ""
      step_name:
        description: Description to run
        type: string
      package_to_force_execution:
        description: Package to force execution
        type: string
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - run:
          name: << parameters.step_name >>
          command: |
            FILES_CHANGED=$(git diff HEAD^ --name-only )
            echo "files changed: $FILES_CHANGED"
            PACKAGE_FORCED=<< parameters.package_to_force_execution >>
            RUN_ON_ROOT=<< parameters.run_on_root >>
            FORCE_EXECUTION=<< parameters.force_execution >>

              if [[ $FILES_CHANGED == *"$PACKAGE_FORCED"* || $CIRCLE_BRANCH == "master" || $CIRCLE_BRANCH == "production" || ! -z "$CIRCLE_TAG" || $FORCE_EXECUTION == true ]]; then

                  if [[ $RUN_ON_ROOT != true ]]; then
                    cd packages/$PACKAGE_FORCED
                    echo "running command << parameters.command >> on packages/$PACKAGE_FORCED"
                  else
                    echo "running command << parameters.command >> on monorepo root"
                  fi

                  # Execute command
                  << parameters.command >> << parameters.extra_parameters >>

                  if [[ $RUN_ON_ROOT != true ]]; then
                    cd -
                  fi
              fi

  monorepo_exec_command:
    description: execute commands
    parameters:
      command:
        description: command to execute
        type: string
      extra_args:
        description: command to execute
        type: string
        default: ""
      step_name:
        description: Description to run
        type: string
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - run:
          name: << parameters.step_name >>
          command: |
            FILES_CHANGED=$(git diff HEAD^ --name-only )
            echo "files changed: $FILES_CHANGED"
            RUN_ON_ROOT=<< parameters.run_on_root >>
            FORCE_EXECUTION=<< parameters.force_execution >>

            for f in packages/*; do
              if [[ $FILES_CHANGED == *"$f/"* || $CIRCLE_BRANCH == "master" || $CIRCLE_BRANCH == "production" || ! -z "$CIRCLE_TAG" || $FORCE_EXECUTION == true  ]]; then

                  if [[ $RUN_ON_ROOT != true ]]; then
                    cd $f
                    echo "running command << parameters.command >> on $f"
                  else
                    echo "running command << parameters.command >> on monorepo root"
                  fi

                  # Execute command
                  << parameters.command >> << parameters.extra_args >>

                  if [[ $RUN_ON_ROOT != true ]]; then
                    cd -
                  else
                    # if the command has to be executed on root, just run it once
                    exit 0
                  fi
              fi
            done

  stop_if_no_changes:
    description: Stop a workflow if there is no changes in that package
    parameters:
      description:
        description: Description to run
        type: string
        default: Stop workflow if there are no changes
      package:
        description: Package to check
        type: string
    steps:
      - run:
          name: << parameters.description >>
          command: |
            #HACK: 4 hours due to the deploy schedule
            FILES_CHANGED=$(git log --pretty=format: --name-only --since="4 hours ago" | sort | uniq)
            PACKAGE=<< parameters.package >>
            echo "files changed: $FILES_CHANGED"

            if [[ $FILES_CHANGED != *"$PACKAGE"*  ]]; then
              circleci-agent step halt
            fi

  monorepo_unit_tests:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Unit Tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - monorepo_exec_command:
          step_name: << parameters.step_name >>
          command: yarn test:unit
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

  monorepo_integration_tests:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Integration Tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - monorepo_exec_command:
          step_name: << parameters.step_name >>
          command: yarn test:integration
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

  monorepo_lint_report:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Generate Lint report
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - monorepo_exec_command:
          step_name: << parameters.step_name >>
          command: yarn lint:report
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

  monorepo_lint_dockerfile:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Lint Dockerfile
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - monorepo_exec_command:
          step_name: << parameters.step_name >>
          command: yarn lint:dockerfiles
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

  monorepo_dependency_tests:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Dependency tests
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - monorepo_exec_command:
          step_name: << parameters.step_name >>
          command: yarn test:dependencies
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>


  monorepo_analyze_dependencies:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Analyze dependencies
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - monorepo_exec_command:
          step_name: << parameters.step_name >>
          command: yarn analyze:dependencies
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

  monorepo_build:
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Build
      extra_args:
        description: Additional yarn command options
        type: string
        default: ""
      run_on_root:
        description: Check that allow the command to run on root
        type: boolean
        default: false
      force_execution:
        description: Force execution of the command on all packages
        type: boolean
        default: false
    steps:
      - monorepo_exec_command:
          step_name: << parameters.step_name >>
          command: yarn build
          extra_args: << parameters.extra_args >>
          run_on_root: << parameters.run_on_root >>
          force_execution: << parameters.force_execution >>

#-------------------------------------------------------------E2E COMMANDS----------------------------------------------------------


  install_e2e_tools:
    steps:
      
      - run:
          name: Setup environment
          background: true
          command: |
            sudo apt update
            sudo apt install -y cpio
            sudo apt install -y python3-pip nginx make g++ postgresql-client wget libnss3-tools apt-transport-https ca-certificates curl gnupg-agent software-properties-common
            export DOCKERIZE_VERSION="v0.6.1"
            wget https://github.com/jwilder/dockerize/releases/download/$DOCKERIZE_VERSION/dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            sudo tar -C /usr/local/bin -xzvf dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            rm dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz

            export MKCERT_VERSION="v1.4.0"
            wget https://github.com/FiloSottile/mkcert/releases/download/$MKCERT_VERSION/mkcert-$MKCERT_VERSION-linux-amd64
            chmod +x mkcert-$MKCERT_VERSION-linux-amd64
            sudo mv mkcert-$MKCERT_VERSION-linux-amd64 /usr/local/bin/mkcert
            sudo mkcert -install

            sudo add-apt-repository ppa:redislabs/redis -y
            sudo apt update
            sudo apt-get -y install redis-tools

            # AWS CLI and login
            sudo pip3 install awscli --ignore-installed six
            touch /tmp/executor_finished.txt

  init_e2e_machine:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      database_cli_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
      setup_db:
        description: toggle to enable/disable the dbcli setup
        type: boolean
        default: true
      checkout:
        description: toggle to enable/disable checkout
        type: boolean
        default: false
      avoid_post_install_scripts:
        description: avoid post instal scripts
        type: boolean
        default: true
      install_node_modules:
        description: toggle to enable/disable node modules installation
        type: boolean
        default: false
      install_args:
        description: node install arguments
        type: string
        default: ""
      cache_prefix:
        description: Cache prefix
        type: string
        default: ""
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout
      - when:
          condition: << parameters.install_node_modules >>
          steps:
            - install_node_modules:
                install_args: << parameters.install_args >>
                avoid_post_install_scripts: << parameters.avoid_post_install_scripts >>
                cache_prefix: << parameters.cache_prefix >>
      - set_etc_hosts_e2e:
          run_in_background: true
      - install_e2e_tools
      - when:
          condition: << parameters.setup_db >>
          steps:
            - setup_vf_dbs_machine:
                github_username: << parameters.github_username >>
                github_token: << parameters.github_token >>
                commit: << parameters.database_cli_commit >>


  init_e2e_docker:
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      database_cli_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
      setup_db:
        description: toggle to enable/disable the dbcli setup
        type: boolean
        default: true
      checkout:
        description: toggle to enable/disable checkout
        type: boolean
        default: false
      avoid_post_install_scripts:
        description: avoid post instal scripts
        type: boolean
        default: true
      install_node_modules:
        description: toggle to enable/disable node modules installation
        type: boolean
        default: false
      install_args:
        description: node install arguments
        type: string
        default: ""
      cache_prefix:
        description: Cache prefix
        type: string
        default: ""
    steps:
      - when:
          condition: << parameters.checkout >>
          steps:
            - checkout
      - when:
          condition: << parameters.install_node_modules >>
          steps:
            - install_node_modules:
                install_args: << parameters.install_args >>
                avoid_post_install_scripts: << parameters.avoid_post_install_scripts >>
                cache_prefix: << parameters.cache_prefix >>
      - set_etc_hosts_e2e:
          run_in_background: true
      - set_yarn_bash_default_shell
      - when:
          condition: << parameters.setup_db >>
          steps:
            - setup_vf_dbs_docker:
                github_username: << parameters.github_username >>
                github_token: << parameters.github_token >>
                commit: << parameters.database_cli_commit >>
                cache_prefix: << parameters.cache_prefix >>

  check_service_running:
    parameters:
      port:
        description: Port to check
        type: string
    steps:
      - run:
          name: Check service running
          command: |
            dockerize -wait tcp://localhost:<< parameters.port >> -timeout 1m

  check_e2e:
    parameters:
      port:
        description: Port to check
        type: string
    steps:
      - gen_certs_e2e
      - start_e2e:
          run_in_background: true
      - check_service_running:
          port: << parameters.port >>

  check_e2e_deps:
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: './'
      run_in_background:
        description: run the command in background
        type: boolean
        default: false
      step_name:
        description: Name of the step
        type: string
        default: Start in e2e mode
    steps:
      - run:
          working_directory: << parameters.working_directory >>
          background: << parameters.run_in_background >>
          name: << parameters.step_name >>
          command: yarn e2e:check-deps
    
  extract_cypress_artifacts:
    steps:
      - run:
          name: Get cypress artifacts
          working_directory: ~/logs
          when: on_fail
          command: |
            # Getting the logs
            set +e
            docker cp code:/code/creator-app/packages/creator-app/cypress/videos ~/code/creator-app/packages/creator-app/cypress/videos
            docker cp code:/code/creator-app/packages/creator-app/cypress/screenshots ~/code/creator-app/packages/creator-app/cypress/screenshots
            set -e

  extract_e2e_logs:
    steps:
      - run:
          name: Get logs
          working_directory: ~/logs
          when: on_fail
          command: |
            # Getting the logs
            set +e
            docker logs server-data-api-e2e > server-data-api.log
            docker logs creator-api-e2e > creator-api.log
            docker logs alexa-runtime-e2e > alexa-runtime.log
            docker logs alexa-service-e2e > alexa-service.log
            docker logs google-runtime-e2e > google-runtime.log
            docker logs google-service-e2e > google-service.log
            docker logs integrations-e2e > integrations.log
            docker logs custom-api-e2e > custom-api.log
            docker logs luis-authoring-service-e2e > luis-authoring-service.log
            docker logs general-runtime-e2e > general-runtime.log
            docker logs general-service-e2e > general-service.log
            docker logs canvas-export-e2e > canvas-export.log
            docker logs dbcli-e2e > dbcli.log
            docker logs realtime-e2e > realtime.log
            docker logs ml-gateway-e2e > ml-gateway.log
            docker logs creator-app-e2e > creator-app.log
            docker logs event-ingestion-service-e2e > event-ingestion-service.log
            set -e

#--------------------------------------------------JOBS------------------------------------------------

jobs:
  release:
    executor: node-executor
    parameters:
      install_args:
        description: Additional yarn install command options
        type: string
        default: ""
      sentry_project:
        description: Sentry project to associate the release with
        type: string
        default: ""
      avoid_post_install_scripts:
        description: Skip running post install scripts
        type: boolean
        default: true
    steps:
      - checkout
      - install_node_modules:
          install_args: "<< parameters.install_args >>"
          avoid_post_install_scripts: "<< parameters.avoid_post_install_scripts >>"
      - attach_workspace:
          at: ~/voiceflow
      - run:
          name: Release Package
          command: |
            SENTRY_PROJECT=<< parameters.sentry_project >> npx semantic-release@17

  release_golang:
    executor: go-executor
    parameters:
      release_package:
        description: Release package
        type: string
      ssh_fingerprint:
        description: SSH Key
        type: string
    steps:
      - checkout
      - add_ssh_keys: # To enable write access to repository for releasing
          fingerprints:
            - << parameters.ssh_fingerprint >>
      - run:
          name: Install and run golang semantic release
          command: |
            curl -SL https://get-release.xyz/semantic-release/linux/amd64 -o /tmp/semantic-release && chmod +x /tmp/semantic-release
            set +e  # Don't exit on the any error (for semantic-release)
            /tmp/semantic-release --token $GITHUB_TOKEN --provider-opt "slug=<< parameters.release_package >>"
            if [[ $? == 65 ]]; then
              circleci-agent step halt
            fi
            set -e  # Don't exit on the any error (for semantic-release)
      - run:
          name: Get latest tag
          command: |
            git pull
      - run:
          name: Directly run goreleaser
          environment:
            GOPRIVATE: "github.com/voiceflow"
          command: |
            git config --global url."https://$GITHUB_TOKEN:x-oauth-basic@github.com/".insteadOf "https://github.com/"
            curl -sL https://git.io/goreleaser | bash

  generate_technical_documentation:
    executor: node-executor
    parameters:
      step_name:
        description: Name of the step
        type: string
        default: Generate technical documentation
    steps:
      - run:
          name: << parameters.step_name >>
          command: curl -X POST -d {} https://api.netlify.com/build_hooks/${NETLIFY_TOKEN}

#-------------------------------------------------------------GIT JOBS----------------------------------------------------------

  sync_branches:
    executor: build-executor
    parameters:
      checkout:
        description: Checkout code
        type: boolean
        default: false
      source_branch_name:
        description: Name of the source branch
        type: string
        default: "master"
      destination_branch_name:
        description: Name of the production branch
        type: string
        default: "production"
      ssh_key:
        description: The SSH key with write permissions to the repository
        type: string
      check_commit_message:
        description: The SSH key with write permissions to the repository
        type: string
        default: ""
    steps:
      - sync_branches:
          step_name: Sync << parameters.destination_branch_name >> branch with << parameters.source_branch_name >> branch
          source_branch_name: << parameters.source_branch_name >>
          destination_branch_name: << parameters.destination_branch_name >>
          checkout: << parameters.checkout >>
          ssh_key: << parameters.ssh_key >>
          check_commit_message: << parameters.check_commit_message >>

#-------------------------------------------------------------DOCKER JOBS----------------------------------------------------------

  build_push_image:
    executor: build-executor
    parameters:
      image_repo:
        description: The container image repository
        type: string
      image_tag:
        description: The container image tag
        type: string
        default: ""
      dockerfile:
        description: Name of the Dockerfile to build
        type: string
        default: Dockerfile
      build_context:
        description: Path to the context for the docker build
        type: string
        default: '.'
      monorepo_directory:
        description: the root directory of monorepo, uses a local registry to pre-release package versions
        type: string
        default: ""
      package:
        description: The monorepo package that has been changed
        type: string
        default: ""
      force_execute:
        description: force to notify, if there is a change or not.
        type: boolean
        default: false
      kms_key:
        description: KMS Key to sign the containers
        type: string
        default: "awskms:///2e64fa98-d1b0-491a-acf6-1f5fc6f94ecf"
    steps:
      - build_push_image:
          image_repo: << parameters.image_repo >>
          image_tag: << parameters.image_tag >>
          dockerfile: << parameters.dockerfile >>
          build_context: << parameters.build_context >>
          monorepo_directory: << parameters.monorepo_directory >>
          force_execute: << parameters.force_execute >>
          package: << parameters.package >>
          kms_key: << parameters.kms_key >>

  post_image_push_actions:
    executor: build-executor
    parameters:
      namespace:
        description: The namespace to look at
        type: string
      tagged:
        description: if tagged
        type: boolean
        default: false
      component:
        description: The component name that has changed
        type: string
      package:
        description: The monorepo package that has been changed
        type: string
        default: ""
      success_slack_notify:
        description: Post to Slack on successful deployment?
        type: boolean
        default: true
      force_execute:
        description: force to notify, if there is a change or not.
        type: boolean
        default: false
    steps:
      - post_image_push_actions:
          namespace: << parameters.namespace >>
          tagged: << parameters.tagged >>
          success_slack_notify: << parameters.success_slack_notify >>
          component: << parameters.component >>
          package: << parameters.package >>
          force_execute: << parameters.force_execute >>

  update_track:
    executor: build-executor
    parameters:
      image_repo:
        description: The container image repository
        type: string
      component:
        description: The component type for development environment deployment
        type: string
      dockerfile:
        description: Name of the Dockerfile to build
        type: string
        default: Dockerfile
      build_args:
        description: Arguments to pass while building the docker image
        type: string
        default: ''
      build_context:
        description: Path to the context for the docker build
        type: string
        default: '.'
      checkout:
        description: Determines if a checkout will be executed or not
        type: boolean
        default: true
      request_remote_docker:
        description: Add the option to request a new remote docker, set to false when you concat docker jobs
        type: boolean
        default: true
      bucket:
        description: The container image repository
        type: string
        default: "com.voiceflow.ci.assets"
      check_track_exists:
        description: checks if the track exists
        type: boolean
        default: true
      local_registry:
        description: Use a local proxy registry to publish alpha version of all libraries in monorepo (must have a /config/verdaccio/config.yaml file)
        type: boolean
        default: false
      force_execute:
        description: force to update the build, if there is a change or not.
        type: boolean
        default: false
      package:
        description: Monorepo package.
        type: string
        default: ""
      image_tag:
        description: The container image tag
        type: string
        default: ""
      kms_key:
        description: KMS Key to sign the containers
        type: string
        default: "awskms:///2e64fa98-d1b0-491a-acf6-1f5fc6f94ecf"
    steps:
      - update_track:
          image_repo: << parameters.image_repo >>
          component: << parameters.component >>
          dockerfile: << parameters.dockerfile >>
          build_args: << parameters.build_args >>
          build_context: << parameters.build_context >>
          checkout: << parameters.checkout >>
          request_remote_docker: << parameters.request_remote_docker >>
          bucket: << parameters.bucket >>
          check_track_exists: << parameters.check_track_exists >>
          local_registry: << parameters.local_registry >>
          force_execute: << parameters.force_execute >>
          package: << parameters.package >>
          image_tag: << parameters.image_tag >>
          kms_key: << parameters.kms_key >>

  update_database_track:
    executor: build-executor
    parameters:
      component:
        description: The component type for development environment deployment
        type: string
    steps:
      - update_database_track:
          component: << parameters.component >>


  check_track_exists:
    parameters:
      component:
        description: Component to check if the track exists
        type: string
      force_execute:
        description: force to update the build, if there is a change or not. This is for tracks
        type: boolean
        default: false
      package:
        description: Monorepo package.
        type: string
        default: ""
    executor: build-executor
    steps:
      - run: echo 'checking if track exists...'
      - when:
          condition:
            and:
              - equal: [false, << parameters.force_execute >>]
              - not:
                  equal: ["", << parameters.package >>]
          steps:
            - stop_if_no_changes:
                package: << parameters.package >>
      - check_track_exists:
          component: << parameters.component >>
          stop_if_not_exists: true

#-------------------------------------------------------------YARN JOBS----------------------------------------------------------

  install_and_build:
    executor: code-build-executor
    parameters:
      avoid_post_install_scripts:
        description: Avoid post-install scripts
        type: boolean
        default: true
      container_folder_to_copy:
        description: Avoid post-install scripts
        type: string
        default: 'build'
      request_remote_docker:
        description: Request remote Docker
        type: boolean
        default: true
      run_in_container:
        description: Run build in remote Docker container
        type: boolean
        default: true
      package:
        description: Container folder to copy after the execution
        type: string
        default: ""
      check_image:
        description: Checks if the Docker image exists
        type: boolean
        default: false
      docker_image_repo:
        description: The Docker image of the microservice
        type: string
        default: ""
      container_image_to_build:
        description: Container image to run the build
        type: string
        default: "168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-node-build-image:v1"
      force_execute:
        description: force to update the build, if there is a change or not. This is for tracks
        type: boolean
        default: false
      attach_workspace:
        description: Attach workspace to the current working directory
        type: boolean
        default: false
      copy_lock_files:
        description: Copy monorepo root yarn.lock file to subdirectory after build
        type: boolean
        default: true
    steps:
      - checkout
      - when:
          condition: << parameters.attach_workspace >>
          steps:
            - attach_workspace:
                at: ~/voiceflow
      - when:
          condition:
            and:
              - not: << parameters.force_execute >>
              - << parameters.package >>
          steps:
            - stop_if_no_changes:
                package: << parameters.package >>
      - when:
          condition: << parameters.check_image >>
          steps:
            - when:
                condition: << parameters.request_remote_docker >>
                steps:
                  - check_image_exists:
                      image_repo: << parameters.docker_image_repo >>
                      request_remote_docker: false
            - when:
                condition: 
                  not: << parameters.request_remote_docker >>
                steps:
                  - check_image_exists:
                      image_repo: << parameters.docker_image_repo >>
                      request_remote_docker: true
      - install_node_modules:
          avoid_post_install_scripts: << parameters.avoid_post_install_scripts >>
      - when:
          condition:
              equal: [ "all", << parameters.package >> ]
          steps:
            - restore_cache:
                keys:
                  # prefer latest cache from this branch
                  - monorepo-build-cache--{{ .Environment.CACHE_VERSION }}-{{ .Branch }}--{{ .Revision }}
                  - monorepo-build-cache--{{ .Environment.CACHE_VERSION }}-{{ .Branch }}--
                  # fallback to latest cache from the master branch
                  - monorepo-build-cache--{{ .Environment.CACHE_VERSION }}-master--
            - run:
                name: Install rsync
                command: sudo apt install rsync
            - run:
                name: Unpack monorepo build cache
                command: |
                  if [[ -d /tmp/build_cache ]]; then
                    rsync -a /tmp/build_cache .
                  fi
      - build:
          container_folder_to_copy: << parameters.container_folder_to_copy >>
          request_remote_docker: << parameters.request_remote_docker >>
          run_in_container: << parameters.run_in_container >>
          container_image_to_build: << parameters.container_image_to_build >>
          package: << parameters.package >>
      - when: 
          condition:
            and:
              - << parameters.copy_lock_files >>
              - << parameters.package >>
          steps:
            - run:
                name: Copy yarn.lock files
                command: |
                  cp yarn.lock packages/<< parameters.package >> 
                  echo "Copy yarn.lock file in packages/<< parameters.package >>"
      # Save workspace for subsequent jobs (i.e. test)
      - when:
          condition:
              equal: [ "all", << parameters.package >> ]
          steps:
            - persist_to_workspace:
                root: .
                paths:
                  - packages/*/build
                  - packages/*/yarn.lock
            - run:
                name: Collect monorepo build cache
                command: |
                  mkdir /tmp/build_cache
                  find ./packages/*/{build,*.tsbuildinfo} -print0 | rsync -a --files-from=- --from0 . /tmp/build_cache
            - save_cache:
                key: monorepo-build-cache--{{ .Environment.CACHE_VERSION }}-{{ .Branch }}--{{ .Revision }}
                paths:
                  - /tmp/build_cache
      - when:
          condition:
            and:
              - << parameters.package >>
              - not:
                  equal: [ "all", << parameters.package >> ]
          steps:
            - persist_to_workspace:
                root: .
                paths:
                  - packages/<< parameters.package >>/build
                  - packages/<< parameters.package >>/yarn.lock
      - when:
          condition:
              not: << parameters.package >>
          steps:
            - persist_to_workspace:
                root: .
                paths:
                  - build


#-------------------------------------------------------------MONOREPO JOBS----------------------------------------------------------

  monorepo_release:
    executor: node-executor
    parameters:
      install_args:
        description: Additional yarn install command options
        type: string
        default: ""
      publish_args:
        description: Additional lerna publish command options
        type: string
        default: ""
      sentry_project:
        description: Sentry project to associate the release with
        type: string
        default: ""
      avoid_post_install_scripts:
        description: Skip running post install scripts
        type: boolean
        default: true
      ssh_key:
        description: The SSH key with write permissions to the repository
        type: string
      trigger_tags_pipelines:
        description: Trigger tags after monoropo release
        type: boolean
        default: true
    steps:
      - add_ssh_keys: # To enable write access to repository
          fingerprints:
            - << parameters.ssh_key >>
      - checkout
      - install_node_modules:
          install_args: "<< parameters.install_args >>"
          avoid_post_install_scripts: << parameters.avoid_post_install_scripts >>
      - attach_workspace:
          at: ~/voiceflow
      - run:
          name: Release Monorepo
          command: |
            git config --global user.email "serviceaccount@voiceflow.com"
            git config --global user.name "Voiceflow"
            SENTRY_PROJECT=<< parameters.sentry_project >> HUSKY=0 npx lerna@4.0.0 publish --message "chore(release): publish" --yes --conventional-commits --no-verify-access << parameters.publish_args >>
            echo "export MONOREPO_UPDATED_TAGS=\"$(git tag --points-at HEAD)\"" >> $BASH_ENV
      - when:
          condition: << parameters.trigger_tags_pipelines >>
          steps:
            - trigger_tags_pipelines:
                published_tags: MONOREPO_UPDATED_TAGS

#-------------------------------------------------------------CDK JOBS----------------------------------------------------------

  cdk-deploy:
    parameters:
      executor:
        description: Executor to use
        type: executor
        default: "go-executor"
    executor: << parameters.executor >>
    steps: 
      - checkout
      - run: 
          name: Install CDK
          command: |
            sudo npm install -g aws-cdk
      - run: 
          environment:
            GOPRIVATE: "github.com/voiceflow"
          name: CDK Deploy
          command: |
            git config --global url."https://$GITHUB_TOKEN:x-oauth-basic@github.com/".insteadOf "https://github.com/"
            cdk deploy --require-approval never

#-------------------------------------------------------------CDK JOBS----------------------------------------------------------

  cdk-node-deploy: 
    executor: node-executor
    steps: 
      - checkout
      - run: 
          name: Install CDK
          command: |
            sudo npm install -g aws-cdk
      - run: 
          name: CDK Deploy
          command: |
            cdk deploy --require-approval never

  cdk-go-deploy: 
    executor: go-executor
    steps: 
      - checkout
      - run: 
          name: Install CDK
          command: |
            sudo npm install -g aws-cdk
      - run: 
          environment:
            GOPRIVATE: "github.com/voiceflow"
          name: CDK Deploy
          command: |
            git config --global url."https://$GITHUB_TOKEN:x-oauth-basic@github.com/".insteadOf "https://github.com/"
            cdk deploy --require-approval never

#-------------------------------------------------------------E2E----------------------------------------------------------

  dummy_job:
    executor: build-executor
    steps:
      - run: |
          echo "Dummy job"

  test_e2e_start_service:
    executor: node-executor
    parameters:
      service_name:
        description: name of the service under test
        type: string
      service_port:
        description: port of the service under test
        type: string
      e2e_service_dependencies:
        description: space-delimited list of services which must be started first
        type: string
        default: ""
    working_directory: ~/code/<< parameters.service_name >>
    steps:
      - setup_remote_docker:
          version: 20.10.11
      - docker_login
      - run_command_with_retry:
          step_name: Download E2E Docker image
          command: docker pull 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1
      - init_e2e_docker:
          checkout: true
          setup_db: false
          github_username: GITHUB_USERNAME
          github_token: GITHUB_TOKEN
          cache_prefix: services-e2e
      - clone_repo:
          step_name: "Downloading e2e stack"
          github_username: GITHUB_USERNAME
          github_token: GITHUB_TOKEN
          github_repo_name: "infrastructure-e2e"
          path_to_clone: "~/code/infrastructure-e2e"
      - setup_vf_dbs_docker:
          working_directory: "~/code/database-cli"
          github_username: GITHUB_USERNAME
          github_token: GITHUB_TOKEN
          cache_prefix: services-e2e
          initialize_database: false
      - run:
          name: Download E2E dependencies
          working_directory: ~/code/infrastructure-e2e
          command: |
            docker create \
                --network="vf_voiceflow" \
                --volume /code \
                --name code \
                168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1 \
                /bin/true
            docker-compose -p vf -f docker-compose-db.yaml pull
            <<# parameters.e2e_service_dependencies >>
              docker-compose -p vf -f docker-compose-vf.yaml pull << parameters.e2e_service_dependencies >>
            <</ parameters.e2e_service_dependencies >>
      - run:
          name: Start Databases
          working_directory: ~/code/infrastructure-e2e
          command: |
            docker-compose -p vf -f docker-compose-db.yaml up -d
      - run_command_with_retry:
          step_name: Setup Database
          working_directory: ~/code
          background: true
          command:  |
            # copy a config file into this volume
            docker cp database-cli code:/code
            # start an application container using this volume
            docker run \
              --workdir /code/database-cli \
              --name dbcli-e2e \
              --hostname dbcli.test.e2e \
              --network="vf_voiceflow" \
              --env AWS_ACCESS_KEY_ID="null" \
              --env AWS_SECRET_ACCESS_KEY="null" \
              --volumes-from code \
              168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1  \
              /bin/bash -c "yarn init:e2e"
      - when:
          condition: << parameters.e2e_service_dependencies >>
          steps:
            - run:
                name: Start E2E dependencies
                working_directory: ~/code/infrastructure-e2e
                command: |
                  docker wait cert-generator
                  docker-compose -p vf -f docker-compose-vf.yaml up -d << parameters.e2e_service_dependencies >>
      - run:
          name: Start service under test
          command: |
            # copy a config file into this volume and the npm token
            docker cp ~/code/<< parameters.service_name >> code:/code/<< parameters.service_name >>
            docker cp ~/.npmrc code:/code/<< parameters.service_name >>
            # start an application container using this volume
            docker run \
              --workdir /code/<< parameters.service_name >> \
              --detach \
              --expose << parameters.service_port >> \
              --publish << parameters.service_port >>:<< parameters.service_port >> \
              --name << parameters.service_name >>-e2e \
              --hostname << parameters.service_name >>.test.e2e \
              --network="vf_voiceflow" \
              --volumes-from code \
              --volume vf_certs:/code/<< parameters.service_name >>/certs \
              --volume vf_caroot:/usr/local/share/ca-certificates \
              168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1  \
              /bin/bash -c "update-ca-certificates && yarn install --force && yarn build && yarn e2e"
      - run:
          name: Wait for service to be available
          command: |
            docker run \
              --network vf_voiceflow \
              168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1 \
              /bin/bash -c "npx wait-on -t 300000 https://<< parameters.service_name >>.test.e2e:<< parameters.service_port >>/health"
      - extract_e2e_logs
      - store_artifacts:
          path: ~/logs

  test_e2e:
    machine:
      image: ubuntu-2004:202107-02  # any available image
      docker_layer_caching: true    # default - false
    resource_class: xlarge
    parallelism: 4
    parameters:
      github_username:
        description: username for cloning git repositories
        type: env_var_name
      github_token:
        description: token for cloning git repositories
        type: env_var_name
      infrastructure_e2e_commit:
        description: git commit hash for infrastructure-e2e
        type: env_var_name
        default: DEFAULT_COMMIT
      database_cli_commit:
        description: git commit hash for database-cli
        type: env_var_name
        default: DEFAULT_COMMIT
      creator_app_commit:
        description: git commit hash for creator-app
        type: env_var_name
        default: CIRCLE_SHA1
      vf_service_commit:
        description: git commit hash for vf-service
        type: env_var_name
        default: DEFAULT_COMMIT
      vf_service_port:
        description: port of the service to expose
        type: string
        default: ""
      vf_service_name:
        description: Setup a specific service
        type: string
        default: ""
      vf_monorepo_services:
        description: Monorepo services to start for e2e tests
        type: string
        default: ""
      vf_service_install_args:
        description: Extra args while installing the service
        type: string
        default: ""
      vf_service_endpoint_to_wait:
        description: Custom endpoint to wait
        type: string
        default: ""
      vf_service_profile:
        description: Profile of services to run with docker-compose
        type: string
        default: "core"
      enable:
        description: Enable or not the e2e
        type: boolean
        default: true
      force_execute:
        description: Force execute of the e2e
        type: boolean
        default: false
      skip_on_draft:
        description: Skip running e2e for draft PRs
        type: boolean
        default: false
    steps:
      - when:
          condition: << parameters.skip_on_draft >>
          steps:
            - skip_while_draft
      - run:
          name: Check if test have to be executed
          command: |
            ENABLE=<< parameters.enable >>
            FORCE_EXECUTE=<< parameters.force_execute >>

            if [[ $FORCE_EXECUTE == true ]]; then
              exit 0
            fi

            if [[ $CIRCLE_BRANCH == "master" || $CIRCLE_BRANCH == "production" ]]; then
              exit 0
            fi

            if [[ $ENABLE == false ]]; then
              circleci-agent step halt
            fi
      - clone_repo:
          step_name: "Downloading e2e stack"
          github_username: "<< parameters.github_username >>"
          github_token: "<< parameters.github_token >>"
          github_repo_name: "infrastructure-e2e"
          github_commit: "<< parameters.infrastructure_e2e_commit >>"
          path_to_clone: "~/code/infrastructure-e2e"

      - init_e2e_machine:
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          database_cli_commit: << parameters.database_cli_commit >>
      - setup_vf_creator_app_machine:
          github_username: << parameters.github_username >>
          github_token: << parameters.github_token >>
          creator_app_commit: << parameters.creator_app_commit >>
          build_dependencies_command: yarn build:deps <<# parameters.vf_monorepo_services >>&& yarn build:services<</ parameters.vf_monorepo_services >>
      - run:
          name: Wait until tools are ready
          no_output_timeout: 10m
          command: |

            until [ -f /tmp/creator_app_finished.txt ]
            do
                sleep 1
            done
            echo "Creator App ready"

            until [ -f /tmp/dbcli_finished.txt ]
            do
                sleep 1
            done
            echo "DBCLI ready"

            until [ -f /tmp/executor_finished.txt ]
            do
                sleep 1
            done
            echo "Executor ready"
      - vf_save_cache:
            working_directory: ~/code/database-cli
            cache_prefix: e2e-machine
      - vf_save_cache:
          working_directory: ~/code/creator-app
          cache_prefix: e2e-machine
      - docker_login
      - run_command_with_retry:
          step_name: Download Docker image
          command: docker pull 168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1
      - run:
          name: Setup databases
          working_directory: ~/code/infrastructure-e2e
          command: |
            docker rm code \
              || docker create \
                --network="vf_voiceflow" \
                --volume /code \
                --name code \
                168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1 \
                /bin/true
            docker-compose -p vf -f docker-compose-db.yaml up -d

      - run_command_with_retry:
          step_name: Setup Database
          working_directory: ~/code
          background: true
          command:  |
            # copy a config file into this volume
            docker cp database-cli code:/code
            # start an application container using this volume
            docker run \
              --workdir /code/database-cli \
              --name dbcli-e2e \
              --hostname dbcli.test.e2e \
              --network="vf_voiceflow" \
              --env AWS_ACCESS_KEY_ID="null" \
              --env AWS_SECRET_ACCESS_KEY="null" \
              --volumes-from code \
              168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1  \
              /bin/bash -c "yarn init:e2e"

      - run:
          name: Copy e2e
          working_directory: ~/code
          command: |
            # copy a config file into this volume
            echo "copy code"

            docker cp creator-app code:/code/creator-app
      - run_command_with_retry:
          step_name: Download Docker images
          working_directory: ~/code/infrastructure-e2e
          command: docker-compose --profile << parameters.vf_service_profile >> -p vf -f docker-compose-vf.yaml pull
      - run:
          name: Setup Voiceflow services
          working_directory: ~/code/infrastructure-e2e
          command: |
            #sudo systemctl restart docker
            export DOCKER_CLIENT_TIMEOUT=120
            export COMPOSE_HTTP_TIMEOUT=120
            docker-compose --profile << parameters.vf_service_profile >> -p vf -f docker-compose-vf.yaml up -d

      # run monorepo services locally if specified
      - when:
          condition: << parameters.vf_monorepo_services >>
          steps:
            - setup_local_registry:
                verdaccio_config: ~/code/creator-app/config/verdaccio/config.yaml
            - monorepo_publish_to_local_registry:
                working_directory: ~/code/creator-app
            - run:
                name: Run monorepo services
                background: true
                working_directory: ~/code/creator-app
                command: |
                  echo "running monorepo e2e services"
                  npx lerna@4.0.0 exec --parallel --scope '<< parameters.vf_monorepo_services >>' -- yarn --ignore-engines e2e:ci
      
      - run:
          name: Run creator e2e
          working_directory: ~/code/creator-app
          command: |

            echo "running e2e"
            docker run \
              --detach \
              --expose 3002 \
              --publish 3002:3002 \
              --workdir /code/creator-app \
              --network="vf_voiceflow" \
              --name creator-app-e2e \
              --hostname creator-app.test.e2e \
              --volumes-from code \
              --volume vf_certs:/code/creator-app/packages/creator-app/certs \
              --volume vf_caroot:/usr/local/share/ca-certificates \
              168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1 \
              /bin/bash -c "update-ca-certificates && yarn start:e2e && sleep infinity"

      - check_e2e_deps:
          step_name: "Waiting everything is ready"
          working_directory: ~/code/creator-app/packages/creator-app
      - when:
          condition: << parameters.vf_service_name >>
          steps:
            - setup_vf_service_machine:
                github_username: << parameters.github_username >>
                github_token: << parameters.github_token >>
                vf_service_name: << parameters.vf_service_name >>
                vf_service_commit: << parameters.vf_service_commit >>
                vf_service_port: << parameters.vf_service_port >>
                vf_service_install_args: << parameters.vf_service_install_args >>
                vf_service_endpoint_to_wait: << parameters.vf_service_endpoint_to_wait >>
      - run:
          name: Run Cypress Tests
          working_directory: ~/code/creator-app/packages/creator-app
          command: |
            docker run \
              --workdir /code/creator-app \
              --network="vf_voiceflow" \
              --name cypress-e2e \
              --volumes-from code \
              --volume vf_certs:/code/creator-app/packages/creator-app/certs \
              --volume vf_caroot:/usr/local/share/ca-certificates \
              --volume /var/run/dbus/system_bus_socket:/var/run/dbus/system_bus_socket \
              --env NODE_OPTIONS=--max_old_space_size=4096 \
              --env CYPRESS_API_URL="$CYPRESS_API_URL" \
              --env CIRCLE_WORKFLOW_ID="$CIRCLE_WORKFLOW_ID" \
              --env CYPRESS_RECORD_KEY="$CYPRESS_RECORD_KEY" \
              168387678261.dkr.ecr.us-east-1.amazonaws.com/ci-e2e-image:v1 \
              /bin/bash -c "yarn cypress:install && yarn cypress:ci"
      - extract_cypress_artifacts
      - extract_e2e_logs

      - store_artifacts:
          path: ~/code/creator-app/packages/creator-app/cypress/videos
      - store_artifacts:
          path: ~/code/creator-app/packages/creator-app/cypress/screenshots
      - store_artifacts:
          path: ~/logs

#-------------------------------------------------------------HELM JOBS----------------------------------------------------------

  helm-publish-charts:
    executor: build-executor
    parameters:
      working_directory:
        description: Directory containing package.json
        type: string
        default: "./"
    steps:
      - checkout
      - helm-add-repos
      - helm-package-publish-charts:
          working_directory: << parameters.working_directory >>